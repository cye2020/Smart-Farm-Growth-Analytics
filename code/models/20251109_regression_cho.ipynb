{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59580449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import platform\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# 2. ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬ \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 2-1. ì‹œê°í™”\n",
    "import plotly.express as px\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "\n",
    "# 2-2. \n",
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from utils import DATA_DIR, MODEL_DIR, REPORT_DIR\n",
    "\n",
    "IMG_DIR = REPORT_DIR / 'figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2062e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "if platform.system() == 'Windows':\n",
    "    plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "elif platform.system() == 'Darwin':  # macOS\n",
    "    plt.rcParams['font.family'] = 'AppleGothic'\n",
    "else:  # Linux\n",
    "    plt.rcParams['font.family'] = 'NanumGothic'\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "# í°íŠ¸ ê°œì¸ ê²½ë¡œì— ë§ì¶°ì„œ ë³€ê²½\n",
    "# FONT_DIR = Path(\"/path/to/fonts\")\n",
    "# font_path = FONT_DIR / 'FREESENTATION-6SEMIBOLD.ttf'\n",
    "# prop = fm.FontProperties(fname=font_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67b870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_kwargs = {\n",
    "    'parse_dates': ['ê²€ì •ì¼ì'],\n",
    "    'date_format': '%Y-%m-%d'\n",
    "}\n",
    "\n",
    "milk: pd.DataFrame = pd.read_csv(DATA_DIR /'interim' / 'milk.csv', **pandas_kwargs)\n",
    "milk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b76b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = milk[milk['ê°€ê²©ë¯¸ë‹¬'] == 0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27501e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'ì „ì‚°ì°¨ê±´ìœ ì „ìœ ëŸ‰', \n",
    "    'ì‚°ì°¨', \n",
    "    'ë†í›„ì‚¬ë£Œê¸‰ì—¬ëŸ‰(ì—°ê³„)', \n",
    "    'ê³µíƒœì¼ìˆ˜', \n",
    "    'ê³„ì ˆ', \n",
    "    'ë†ì¥êµ¬ë¶„', \n",
    "    'ë¶„ë§Œê°„ê²©',\n",
    "    # 'ì •ì•¡ì½”ë“œë¶„ë¥˜'\n",
    "]\n",
    "\n",
    "target = 'ê°€ê²©'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ce3f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================\n",
    "# 0. ì €ì¥ ë””ë ‰í† ë¦¬ ë° íƒ€ì„ìŠ¤íƒ¬í”„ ì„¤ì •\n",
    "# ============================================\n",
    "\n",
    "# í˜„ì¬ ì‹œê° ì¸¡ì • (ëª¨ë“  íŒŒì¼ì— ë™ì¼í•˜ê²Œ ì‚¬ìš©)\n",
    "TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# ëª¨ë“  íŒŒì¼ ê²½ë¡œ ë¯¸ë¦¬ ì •ì˜\n",
    "PATHS = {\n",
    "    'log': MODEL_DIR / f'optuna_xgboost_{TIMESTAMP}.log',\n",
    "    'db': f'sqlite:///{MODEL_DIR / f\"optuna_xgboost_{TIMESTAMP}.db\"}',\n",
    "    'intermediate': MODEL_DIR / f'intermediate_results_{TIMESTAMP}.json',\n",
    "    'best_params': MODEL_DIR / f'best_params_{TIMESTAMP}.json',\n",
    "    'all_trials': MODEL_DIR / f'all_trials_{TIMESTAMP}.csv',\n",
    "    'test_results': MODEL_DIR / f'test_results_{TIMESTAMP}.json',\n",
    "    'predictions': MODEL_DIR / f'test_predictions_{TIMESTAMP}.csv',\n",
    "    'feature_importance': MODEL_DIR / f'feature_importance_{TIMESTAMP}.csv',\n",
    "    'final_model': MODEL_DIR / f'xgboost_final_model_{TIMESTAMP}.pkl',\n",
    "    'final_report': MODEL_DIR / f'final_report_{TIMESTAMP}.txt',\n",
    "    # ì‹œê°í™” íŒŒì¼ë“¤\n",
    "    'viz_history': IMG_DIR / f'optuna_optimization_history_{TIMESTAMP}.html',\n",
    "    'viz_importance': IMG_DIR / f'optuna_param_importances_{TIMESTAMP}.html',\n",
    "    'viz_contour': IMG_DIR / f'optuna_contour_{TIMESTAMP}.html',\n",
    "    'viz_parallel': IMG_DIR / f'optuna_parallel_coordinate_{TIMESTAMP}.html',\n",
    "    'viz_slice': IMG_DIR / f'optuna_slice_{TIMESTAMP}.html',\n",
    "}\n",
    "\n",
    "# ============================================\n",
    "# 1. ë¡œê¹… ì„¤ì •\n",
    "# ============================================\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(PATHS['log']),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(f\"ğŸ“ ì €ì¥ ë””ë ‰í† ë¦¬: {MODEL_DIR.absolute()}\")\n",
    "logger.info(f\"â° íƒ€ì„ìŠ¤íƒ¬í”„: {TIMESTAMP}\")\n",
    "\n",
    "# ============================================\n",
    "# 2. ë©€í‹° GPU ì„¤ì •\n",
    "# ============================================\n",
    "AVAILABLE_GPUS = [0, 1, 2, 3]  # ë‹¹ì‹ ì˜ GPU ê°œìˆ˜ì— ë§ê²Œ ìˆ˜ì •\n",
    "NUM_GPUS = len(AVAILABLE_GPUS)\n",
    "\n",
    "logger.info(f\"ğŸ® ì‚¬ìš© ê°€ëŠ¥í•œ GPU: {AVAILABLE_GPUS}\")\n",
    "\n",
    "def get_gpu_id(trial_number):\n",
    "    \"\"\"Trial ë²ˆí˜¸ì— ë”°ë¼ GPU í• ë‹¹ (ë¼ìš´ë“œ ë¡œë¹ˆ ë°©ì‹)\"\"\"\n",
    "    return AVAILABLE_GPUS[trial_number % NUM_GPUS]\n",
    "\n",
    "# ============================================\n",
    "# 3. ë°ì´í„° ì¤€ë¹„\n",
    "# ============================================\n",
    "logger.info(\"ğŸ“ ë°ì´í„° ë¡œë”© ì¤‘...\")\n",
    "\n",
    "split_date = '2021-08-01'\n",
    "train = df[df['ê²€ì •ì¼ì'] < split_date]\n",
    "test = df[df['ê²€ì •ì¼ì'] >= split_date]\n",
    "\n",
    "X_train, X_test = train[features], test[features]\n",
    "y_train, y_test = train[target], test[target]\n",
    "\n",
    "logger.info(f\"  í›ˆë ¨ ë°ì´í„°: {X_train.shape}\")\n",
    "logger.info(f\"  í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}\")\n",
    "\n",
    "# ============================================\n",
    "# 4. ì¤‘ê°„ ê²°ê³¼ ì €ì¥ í•¨ìˆ˜ (optimize ì „ì— ì •ì˜ í•„ìš”)\n",
    "# ============================================\n",
    "def save_intermediate_results(study, trial):\n",
    "    \"\"\"10ë²ˆë§ˆë‹¤ ì¤‘ê°„ ê²°ê³¼ ì €ì¥\"\"\"\n",
    "    logger.info(f\"\\nğŸ’¾ ì¤‘ê°„ ì €ì¥ (Trial {trial.number})\")\n",
    "    \n",
    "    intermediate_results = {\n",
    "        'timestamp': TIMESTAMP,\n",
    "        'saved_at': datetime.now().isoformat(),\n",
    "        'trial_number': trial.number,\n",
    "        'best_value': study.best_value,\n",
    "        'best_params': study.best_params,\n",
    "        'n_trials': len(study.trials)\n",
    "    }\n",
    "    \n",
    "    with open(PATHS['intermediate'], 'w') as f:\n",
    "        json.dump(intermediate_results, f, indent=2)\n",
    "\n",
    "# ============================================\n",
    "# 5. Objective í•¨ìˆ˜ (ë©€í‹° GPU ë²„ì „)\n",
    "# ============================================\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna ëª©ì  í•¨ìˆ˜ - ë©€í‹° GPU ì§€ì›\n",
    "    \"\"\"\n",
    "    # 5-1. GPU í• ë‹¹\n",
    "    gpu_id = get_gpu_id(trial.number)\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "    \n",
    "    logger.info(f\"Trial {trial.number}: GPU {gpu_id} ì‚¬ìš©\")\n",
    "    \n",
    "    # 5-2. íŒŒë¼ë¯¸í„° ì œì•ˆ\n",
    "    params = {\n",
    "        # ========== ëª¨ë¸ ë³µì¡ë„ ==========\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        \n",
    "        # ========== í•™ìŠµ ì†ë„ & ë°˜ë³µ ==========\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=50),\n",
    "        \n",
    "        # ========== ìƒ˜í”Œë§ ==========\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0),\n",
    "        \n",
    "        # ========== ì •ê·œí™” ==========\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        \n",
    "        # ========== GPU & ê¸°íƒ€ ==========\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'gpu_id': gpu_id,\n",
    "        'predictor': 'gpu_predictor',\n",
    "        'random_state': 42,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "    # 5-3. ëª¨ë¸ ìƒì„± ë° êµì°¨ ê²€ì¦\n",
    "    try:\n",
    "        model = XGBRegressor(**params)\n",
    "        \n",
    "        cv_scores = cross_val_score(\n",
    "            model, X_train, y_train,\n",
    "            cv=5,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            n_jobs=1\n",
    "        )\n",
    "        \n",
    "        mean_mse = -cv_scores.mean()\n",
    "        \n",
    "        # Trialì— ì¶”ê°€ ì •ë³´ ì €ì¥\n",
    "        trial.set_user_attr('cv_std', cv_scores.std())\n",
    "        trial.set_user_attr('cv_scores', cv_scores.tolist())\n",
    "        trial.set_user_attr('gpu_id', gpu_id)\n",
    "        \n",
    "        return mean_mse\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Trial {trial.number} ì‹¤íŒ¨: {str(e)}\")\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "# ============================================\n",
    "# 6. Optuna Study ìƒì„± (DB ì €ì¥)\n",
    "# ============================================\n",
    "STUDY_NAME = f'xgboost_regression_{TIMESTAMP}'\n",
    "\n",
    "logger.info(f\"ğŸ—„ï¸  ë°ì´í„°ë² ì´ìŠ¤: {PATHS['db']}\")\n",
    "logger.info(f\"ğŸ“š Study ì´ë¦„: {STUDY_NAME}\")\n",
    "\n",
    "# Study ìƒì„± ë˜ëŠ” ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "study = optuna.create_study(\n",
    "    study_name=STUDY_NAME,\n",
    "    storage=PATHS['db'],\n",
    "    load_if_exists=True,\n",
    "    direction='minimize',\n",
    "    sampler=optuna.samplers.TPESampler(\n",
    "        seed=42,\n",
    "        n_startup_trials=20,\n",
    "        multivariate=True\n",
    "    ),\n",
    "    pruner=optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=10,\n",
    "        n_warmup_steps=5\n",
    "    )\n",
    ")\n",
    "\n",
    "# ì´ì „ ì‹¤í–‰ ì •ë³´ ì¶œë ¥\n",
    "if len(study.trials) > 0:\n",
    "    logger.info(f\"âœ… ì´ì „ ì‹¤í–‰ ë°œê²¬: {len(study.trials)}ê°œ trials\")\n",
    "    logger.info(f\"   í˜„ì¬ ìµœì  MSE: {study.best_value:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# 7. ìµœì í™” ì‹¤í–‰\n",
    "# ============================================\n",
    "N_TRIALS = 300\n",
    "TIMEOUT = None\n",
    "\n",
    "logger.info(\"\\n\" + \"=\"*60)\n",
    "logger.info(\"ğŸš€ Optuna ìµœì í™” ì‹œì‘!\")\n",
    "logger.info(f\"   ëª©í‘œ Trials: {N_TRIALS}\")\n",
    "logger.info(f\"   ë©€í‹° GPU: {NUM_GPUS}ê°œ\")\n",
    "logger.info(\"=\"*60 + \"\\n\")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=N_TRIALS,\n",
    "    timeout=TIMEOUT,\n",
    "    n_jobs=1,\n",
    "    show_progress_bar=True,\n",
    "    callbacks=[\n",
    "        lambda study, trial: save_intermediate_results(study, trial) \n",
    "        if trial.number % 10 == 0 else None\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 8. ìµœì í™” ê²°ê³¼ ë¶„ì„ ë° ì €ì¥\n",
    "# ============================================\n",
    "logger.info(\"\\n\" + \"=\"*60)\n",
    "logger.info(\"âœ… ìµœì í™” ì™„ë£Œ!\")\n",
    "logger.info(\"=\"*60)\n",
    "\n",
    "# 8-1. ê¸°ë³¸ í†µê³„\n",
    "logger.info(f\"\\nğŸ“Š íƒìƒ‰ í†µê³„:\")\n",
    "logger.info(f\"  ì´ ì‹œë„: {len(study.trials)}\")\n",
    "logger.info(f\"  ì™„ë£Œ: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}\")\n",
    "logger.info(f\"  ê°€ì§€ì¹˜ê¸°: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "logger.info(f\"  ì‹¤íŒ¨: {len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL])}\")\n",
    "\n",
    "# 8-2. ìµœì  íŒŒë¼ë¯¸í„°\n",
    "logger.info(f\"\\nğŸ† ìµœì  íŒŒë¼ë¯¸í„°:\")\n",
    "for key, value in study.best_params.items():\n",
    "    logger.info(f\"  {key:20s}: {value}\")\n",
    "\n",
    "logger.info(f\"\\nğŸ¯ ìµœì  CV MSE: {study.best_value:.6f}\")\n",
    "\n",
    "# ============================================\n",
    "# 9. ìµœì  íŒŒë¼ë¯¸í„° ì €ì¥ (JSON)\n",
    "# ============================================\n",
    "best_params_with_meta = {\n",
    "    'timestamp': TIMESTAMP,\n",
    "    'study_name': STUDY_NAME,\n",
    "    'n_trials': len(study.trials),\n",
    "    'best_value': study.best_value,\n",
    "    'best_params': study.best_params,\n",
    "    'cv_std': study.best_trial.user_attrs.get('cv_std', None),\n",
    "    'gpu_id_used': study.best_trial.user_attrs.get('gpu_id', None)\n",
    "}\n",
    "\n",
    "with open(PATHS['best_params'], 'w') as f:\n",
    "    json.dump(best_params_with_meta, f, indent=2)\n",
    "\n",
    "logger.info(f\"\\nğŸ’¾ ì €ì¥: {PATHS['best_params'].name}\")\n",
    "\n",
    "# ============================================\n",
    "# 10. ì „ì²´ Trials ì •ë³´ ì €ì¥ (CSV)\n",
    "# ============================================\n",
    "trials_df = study.trials_dataframe()\n",
    "trials_df.to_csv(PATHS['all_trials'], index=False)\n",
    "logger.info(f\"ğŸ’¾ ì €ì¥: {PATHS['all_trials'].name}\")\n",
    "\n",
    "# ============================================\n",
    "# 11. ìµœì¢… ëª¨ë¸ í•™ìŠµ\n",
    "# ============================================\n",
    "logger.info(\"\\n\" + \"=\"*60)\n",
    "logger.info(\"ğŸ”§ ìµœì¢… ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "logger.info(\"=\"*60)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(AVAILABLE_GPUS[0])\n",
    "\n",
    "best_params_final = study.best_params.copy()\n",
    "best_params_final.update({\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'gpu_id': 0,\n",
    "    'predictor': 'gpu_predictor',\n",
    "    'random_state': 42,\n",
    "    'verbosity': 1\n",
    "})\n",
    "\n",
    "final_model = XGBRegressor(**best_params_final)\n",
    "\n",
    "final_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    eval_metric=['rmse', 'mae'],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 12. í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ í‰ê°€\n",
    "# ============================================\n",
    "logger.info(\"\\n\" + \"=\"*60)\n",
    "logger.info(\"ğŸ“Š í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€\")\n",
    "logger.info(\"=\"*60)\n",
    "\n",
    "y_pred_train = final_model.predict(X_train)\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "\n",
    "# í›ˆë ¨ ì„¸íŠ¸ ì„±ëŠ¥\n",
    "train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì„±ëŠ¥\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "logger.info(f\"\\nğŸ“ í›ˆë ¨ ì„¸íŠ¸:\")\n",
    "logger.info(f\"  MSE  : {train_mse:.6f}\")\n",
    "logger.info(f\"  RMSE : {train_rmse:.6f}\")\n",
    "logger.info(f\"  MAE  : {train_mae:.6f}\")\n",
    "logger.info(f\"  RÂ²   : {train_r2:.6f}\")\n",
    "\n",
    "logger.info(f\"\\nğŸ¯ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸:\")\n",
    "logger.info(f\"  MSE  : {test_mse:.6f}\")\n",
    "logger.info(f\"  RMSE : {test_rmse:.6f}\")\n",
    "logger.info(f\"  MAE  : {test_mae:.6f}\")\n",
    "logger.info(f\"  RÂ²   : {test_r2:.6f}\")\n",
    "\n",
    "# ê³¼ì í•© ì²´í¬\n",
    "overfitting_ratio = (train_mse - test_mse) / train_mse * 100\n",
    "logger.info(f\"\\nâš ï¸  ê³¼ì í•© ì§€í‘œ: {overfitting_ratio:.2f}%\")\n",
    "if overfitting_ratio > 20:\n",
    "    logger.warning(\"  â†’ ê³¼ì í•© ì˜ì‹¬! ì •ê·œí™” ê°•í™” ê³ ë ¤\")\n",
    "elif overfitting_ratio < -10:\n",
    "    logger.warning(\"  â†’ ê³¼ì†Œì í•© ì˜ì‹¬! ëª¨ë¸ ë³µì¡ë„ ì¦ê°€ ê³ ë ¤\")\n",
    "else:\n",
    "    logger.info(\"  â†’ ì ì ˆí•œ ì¼ë°˜í™” ì„±ëŠ¥ âœ…\")\n",
    "\n",
    "# ============================================\n",
    "# 13. í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ (JSON)\n",
    "# ============================================\n",
    "test_results = {\n",
    "    'timestamp': TIMESTAMP,\n",
    "    'model': 'XGBRegressor',\n",
    "    'optimization': 'Optuna',\n",
    "    'n_trials': len(study.trials),\n",
    "    'best_cv_mse': study.best_value,\n",
    "    \n",
    "    'train_metrics': {\n",
    "        'mse': float(train_mse),\n",
    "        'rmse': float(train_rmse),\n",
    "        'mae': float(train_mae),\n",
    "        'r2': float(train_r2)\n",
    "    },\n",
    "    \n",
    "    'test_metrics': {\n",
    "        'mse': float(test_mse),\n",
    "        'rmse': float(test_rmse),\n",
    "        'mae': float(test_mae),\n",
    "        'r2': float(test_r2)\n",
    "    },\n",
    "    \n",
    "    'overfitting_ratio': float(overfitting_ratio),\n",
    "    'best_params': study.best_params,\n",
    "    \n",
    "    'training_info': {\n",
    "        'train_size': len(X_train),\n",
    "        'test_size': len(X_test),\n",
    "        'n_features': X_train.shape[1],\n",
    "        'early_stopping_rounds': 50,\n",
    "        'best_iteration': int(final_model.best_iteration) if hasattr(final_model, 'best_iteration') else None\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(PATHS['test_results'], 'w') as f:\n",
    "    json.dump(test_results, f, indent=2)\n",
    "\n",
    "logger.info(f\"\\nğŸ’¾ ì €ì¥: {PATHS['test_results'].name}\")\n",
    "\n",
    "# ============================================\n",
    "# 14. ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ (CSV)\n",
    "# ============================================\n",
    "predictions_df = pd.DataFrame({\n",
    "    'y_true': y_test,\n",
    "    'y_pred': y_pred_test,\n",
    "    'error': y_test - y_pred_test,\n",
    "    'abs_error': np.abs(y_test - y_pred_test),\n",
    "    'squared_error': (y_test - y_pred_test) ** 2\n",
    "})\n",
    "\n",
    "predictions_df.to_csv(PATHS['predictions'], index=False)\n",
    "logger.info(f\"ğŸ’¾ ì €ì¥: {PATHS['predictions'].name}\")\n",
    "\n",
    "# ============================================\n",
    "# 15. Feature Importance ì €ì¥\n",
    "# ============================================\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importance.to_csv(PATHS['feature_importance'], index=False)\n",
    "logger.info(f\"ğŸ’¾ ì €ì¥: {PATHS['feature_importance'].name}\")\n",
    "\n",
    "logger.info(\"\\nğŸ” Top 10 ì¤‘ìš” Features:\")\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    logger.info(f\"  {row['feature']:20s}: {row['importance']:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# 16. ìµœì¢… ëª¨ë¸ ì €ì¥ (Pickle)\n",
    "# ============================================\n",
    "joblib.dump(final_model, PATHS['final_model'])\n",
    "logger.info(f\"\\nğŸ’¾ ì €ì¥: {PATHS['final_model'].name}\")\n",
    "\n",
    "# ============================================\n",
    "# 17. Optuna ì‹œê°í™”\n",
    "# ============================================\n",
    "logger.info(\"\\n\" + \"=\"*60)\n",
    "logger.info(\"ğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...\")\n",
    "logger.info(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # 17-1. ìµœì í™” ê³¼ì •\n",
    "    fig1 = optuna.visualization.plot_optimization_history(study)\n",
    "    fig1.write_html(str(PATHS['viz_history']))\n",
    "    logger.info(f\"âœ… {PATHS['viz_history'].name}\")\n",
    "    \n",
    "    # 17-2. íŒŒë¼ë¯¸í„° ì¤‘ìš”ë„\n",
    "    fig2 = optuna.visualization.plot_param_importances(study)\n",
    "    fig2.write_html(str(PATHS['viz_importance']))\n",
    "    logger.info(f\"âœ… {PATHS['viz_importance'].name}\")\n",
    "    \n",
    "    # 17-3. íŒŒë¼ë¯¸í„° ê´€ê³„ë„\n",
    "    fig3 = optuna.visualization.plot_contour(study, params=['learning_rate', 'max_depth'])\n",
    "    fig3.write_html(str(PATHS['viz_contour']))\n",
    "    logger.info(f\"âœ… {PATHS['viz_contour'].name}\")\n",
    "    \n",
    "    # 17-4. ë³‘ë ¬ ì¢Œí‘œ í”Œë¡¯\n",
    "    fig4 = optuna.visualization.plot_parallel_coordinate(study)\n",
    "    fig4.write_html(str(PATHS['viz_parallel']))\n",
    "    logger.info(f\"âœ… {PATHS['viz_parallel'].name}\")\n",
    "    \n",
    "    # 17-5. Slice í”Œë¡¯\n",
    "    fig5 = optuna.visualization.plot_slice(study)\n",
    "    fig5.write_html(str(PATHS['viz_slice']))\n",
    "    logger.info(f\"âœ… {PATHS['viz_slice'].name}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.warning(f\"ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}\")\n",
    "\n",
    "# ============================================\n",
    "# 18. ìµœì¢… ìš”ì•½ ë¦¬í¬íŠ¸ ì €ì¥\n",
    "# ============================================\n",
    "summary_report = f\"\"\"\n",
    "{'='*60}\n",
    "XGBoost + Optuna ìµœì í™” ìµœì¢… ë¦¬í¬íŠ¸\n",
    "{'='*60}\n",
    "\n",
    "ğŸ“… ì‹¤í–‰ ì‹œê°„: {TIMESTAMP}\n",
    "ğŸ“ ì €ì¥ ìœ„ì¹˜: {MODEL_DIR.absolute()}\n",
    "\n",
    "ğŸ® GPU ì„¤ì •:\n",
    "  - ì‚¬ìš© GPU: {AVAILABLE_GPUS}\n",
    "  - GPU ê°œìˆ˜: {NUM_GPUS}\n",
    "\n",
    "ğŸ” ìµœì í™” ì„¤ì •:\n",
    "  - Study ì´ë¦„: {STUDY_NAME}\n",
    "  - ì´ Trials: {len(study.trials)}\n",
    "  - ì™„ë£Œëœ Trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])}\n",
    "\n",
    "ğŸ† ìµœì  íŒŒë¼ë¯¸í„°:\n",
    "{json.dumps(study.best_params, indent=2)}\n",
    "\n",
    "ğŸ“Š ì„±ëŠ¥ ì§€í‘œ:\n",
    "  \n",
    "  í›ˆë ¨ ì„¸íŠ¸:\n",
    "    - MSE  : {train_mse:.6f}\n",
    "    - RMSE : {train_rmse:.6f}\n",
    "    - MAE  : {train_mae:.6f}\n",
    "    - RÂ²   : {train_r2:.6f}\n",
    "  \n",
    "  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸:\n",
    "    - MSE  : {test_mse:.6f}\n",
    "    - RMSE : {test_rmse:.6f}\n",
    "    - MAE  : {test_mae:.6f}\n",
    "    - RÂ²   : {test_r2:.6f}\n",
    "  \n",
    "  ê³¼ì í•© ë¹„ìœ¨: {overfitting_ratio:.2f}%\n",
    "\n",
    "ğŸ’¾ ì €ì¥ëœ íŒŒì¼:\n",
    "  - {PATHS['best_params'].name}\n",
    "  - {PATHS['test_results'].name}\n",
    "  - {PATHS['all_trials'].name}\n",
    "  - {PATHS['predictions'].name}\n",
    "  - {PATHS['feature_importance'].name}\n",
    "  - {PATHS['final_model'].name}\n",
    "  - {PATHS['db'].split('///')[-1]}\n",
    "  - {PATHS['log'].name}\n",
    "  - {PATHS['viz_history'].name}\n",
    "  - {PATHS['viz_importance'].name}\n",
    "  - {PATHS['viz_contour'].name}\n",
    "  - {PATHS['viz_parallel'].name}\n",
    "  - {PATHS['viz_slice'].name}\n",
    "\n",
    "{'='*60}\n",
    "\"\"\"\n",
    "\n",
    "with open(PATHS['final_report'], 'w', encoding='utf-8') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "logger.info(f\"\\nğŸ’¾ ì €ì¥: {PATHS['final_report'].name}\")\n",
    "logger.info(summary_report)\n",
    "\n",
    "logger.info(\"\\n\" + \"=\"*60)\n",
    "logger.info(\"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!\")\n",
    "logger.info(f\"ğŸ“ ëª¨ë“  íŒŒì¼ì´ {MODEL_DIR.absolute()} ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤\")\n",
    "logger.info(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartfarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
