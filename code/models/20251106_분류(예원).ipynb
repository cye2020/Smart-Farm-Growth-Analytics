{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70d84cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lizzy\\OneDrive\\ë°”íƒ• í™”ë©´\\ì‹¤ì „í”„ë¡œì íŠ¸\\code\\models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\lizzy\\OneDrive\\ë°”íƒ• í™”ë©´\\ì‹¤ì „í”„ë¡œì íŠ¸\\code\\models\")\n",
    "print(os.getcwd())  # ì˜ ë°”ë€Œì—ˆëŠ”ì§€ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98092ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lizzy\\ìŠ¤íŒŒë¥´íƒ€_íŒŒì´ì¬\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28021e0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'missingno'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report, balanced_accuracy_score, roc_auc_score\n\u001b[32m     36\u001b[39m sys.path.append(\u001b[38;5;28mstr\u001b[39m(Path.cwd().parent))\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DATA_DIR, MODEL_DIR\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\ë°”íƒ• í™”ë©´\\ì‹¤ì „í”„ë¡œì íŠ¸\\code\\utils\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PROJECT_DIR, CODE_DIR, DATA_DIR, MODEL_DIR, \\\n\u001b[32m      2\u001b[39m     growth_map, energy_map\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01meda\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m eda_missing_data, eda_duplicates, plot_features\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstatistic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TTest\n\u001b[32m      6\u001b[39m __all__ = [\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mPROJECT_DIR\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCODE_DIR\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mDATA_DIR\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMODEL_DIR\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mgrowth_map\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33menergy_map\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33meda_missing_data\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33meda_duplicates\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mplot_features\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mTTest\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     11\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\ë°”íƒ• í™”ë©´\\ì‹¤ì „í”„ë¡œì íŠ¸\\code\\utils\\eda.py:8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmissingno\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmsno\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stats\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'missingno'"
     ]
    }
   ],
   "source": [
    "# 1. í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import platform\n",
    "import time\n",
    "import os\n",
    "\n",
    "# 2. ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬ \n",
    "\n",
    "# 2-1. ì‹œê°í™”\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "\n",
    "# 2-2. \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report, balanced_accuracy_score, roc_auc_score\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from utils import DATA_DIR, MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e26762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "if platform.system() == 'Windows':\n",
    "    plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "elif platform.system() == 'Darwin':  # macOS\n",
    "    plt.rcParams['font.family'] = 'AppleGothic'\n",
    "else:  # Linux\n",
    "    plt.rcParams['font.family'] = 'NanumGothic'\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "# í°íŠ¸ ê°œì¸ ê²½ë¡œì— ë§ì¶°ì„œ ë³€ê²½\n",
    "# FONT_DIR = Path(\"/path/to/fonts\")\n",
    "# font_path = FONT_DIR / 'FREESENTATION-6SEMIBOLD.ttf'\n",
    "# prop = fm.FontProperties(fname=font_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced663af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m milk = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m\"\u001b[39m\u001b[33mdata/interim/milk.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m milk[\u001b[33m'\u001b[39m\u001b[33mê²€ì •ì¼ì\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(\n\u001b[32m      4\u001b[39m     milk[\u001b[33m'\u001b[39m\u001b[33mê²€ì •ì¼ì\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mformat\u001b[39m=\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m      6\u001b[39m     errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;66;03m# ë³€í™˜ ì•ˆ ë˜ëŠ” ê°’ì€ NaTë¡œ ì²˜ë¦¬\u001b[39;00m\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m milk.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "milk = pd.read_csv(\"data/interim/milk.csv\")\n",
    "\n",
    "milk['ê²€ì •ì¼ì'] = pd.to_datetime(\n",
    "    milk['ê²€ì •ì¼ì'],\n",
    "    format='%Y-%m-%d',\n",
    "    errors='coerce'  # ë³€í™˜ ì•ˆ ë˜ëŠ” ê°’ì€ NaTë¡œ ì²˜ë¦¬\n",
    ")\n",
    "\n",
    "milk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878e8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = milk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551af10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['1ë“±ê¸‰'] = df['ìš°ìœ ë“±ê¸‰'].map({\n",
    "    '1ë“±ê¸‰': 1,\n",
    "    '2ë“±ê¸‰ì´í•˜': 0\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4083ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "target='1ë“±ê¸‰'\n",
    "features = [\n",
    "    'ëˆ„ì ì°©ìœ ì¼(ì—°ê³„)',\n",
    "    'ì „ì‚°ì°¨ë¹„ìœ ì§€ì†ì„±',\n",
    "    'í˜„ì¬ì‚°ì°¨ë¹„ìœ ì§€ì†ì„±',\n",
    "    'ë¹„ìœ ìµœê³ ë„ë‹¬ì¼ìˆ˜_log',\n",
    "    'ê±´ìœ ì „ë§ˆì§€ë§‰ìœ ëŸ‰_log',\n",
    "    'ì „ì‚°ì°¨ê±´ìœ ì „ìœ ëŸ‰',\n",
    "    'ì‚°ì°¨',\n",
    "    'ë†í›„ì‚¬ë£Œê¸‰ì—¬ëŸ‰(ì—°ê³„)',\n",
    "    'ê³µíƒœì¼ìˆ˜_log'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['ê²€ì •ì¼ì'].dt.year == 2020]\n",
    "test = df[df['ê²€ì •ì¼ì'].dt.year == 2021]\n",
    "\n",
    "X_train, X_test = train[features], test[features]\n",
    "y_train, y_test = train['1ë“±ê¸‰'], test['1ë“±ê¸‰']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01265e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, make_scorer, recall_score,\n",
    "    precision_score, f1_score, fbeta_score, roc_auc_score,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline  # imblearnì˜ Pipeline ì‚¬ìš©\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from scipy.stats import uniform, randint\n",
    "# (í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ - ì´ë¯¸ ìŠ¤í¬ë¦½íŠ¸ì— ìˆì„ ê²ƒì…ë‹ˆë‹¤)\n",
    "\n",
    "# (X_train, y_train, X_test, y_test ë“±ì´ ì´ë¯¸ ë¡œë“œë˜ì—ˆë‹¤ê³  ê°€ì •)\n",
    "\n",
    "# ============================================\n",
    "# 1. í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„ (ìˆ˜ì •ë¨)\n",
    "# ============================================\n",
    "print(\"=\"*60)\n",
    "print(\"í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„\")\n",
    "print(\"=\"*60)\n",
    "print(y_train.value_counts().sort_index())\n",
    "print(f\"\\në¹„ìœ¨:\")\n",
    "print(y_train.value_counts(normalize=True).sort_index())\n",
    "\n",
    "# ğŸ”¥ ìˆ˜ì •: 0ì´ ì†Œìˆ˜, 1ì´ ë‹¤ìˆ˜ (ì£¼ì„ê³¼ ì¼ì¹˜í•˜ë„ë¡ ìˆ˜ì •)\n",
    "minority_count = (y_train == 0).sum()  # 0 (ê·¸ì™¸, ì†Œìˆ˜)\n",
    "majority_count = (y_train == 1).sum()  # 1 (1ë“±ê¸‰, ë‹¤ìˆ˜)\n",
    "\n",
    "print(f\"\\ní´ë˜ìŠ¤ êµ¬ì„± (ìˆ˜ì •ë¨):\")\n",
    "print(f\"   0 (ê·¸ì™¸, ì†Œìˆ˜): {minority_count}ê°œ ({minority_count/len(y_train)*100:.1f}%)\")\n",
    "print(f\"   1 (1ë“±ê¸‰, ë‹¤ìˆ˜): {majority_count}ê°œ ({majority_count/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "# LGBMì˜ scale_pos_weightëŠ” (ë‹¤ìˆ˜ ìƒ˜í”Œ ìˆ˜ / ì†Œìˆ˜ ìƒ˜í”Œ ìˆ˜)\n",
    "# ì°¸ê³ : ì´ ê°’ì€ ì •ë³´ìš©ì´ë©°, ì‹¤ì œ íŠœë‹ì€ param_distributionsì—ì„œ ìˆ˜í–‰ë©ë‹ˆë‹¤.\n",
    "calculated_scale_pos_weight = majority_count / minority_count\n",
    "print(f\"\\nê³„ì‚°ëœ LGBM scale_pos_weight (ë‹¤ìˆ˜/ì†Œìˆ˜): {calculated_scale_pos_weight:.2f}\")\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ í™•ì¸ (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "print(\"\\nê²°ì¸¡ì¹˜ í˜„í™©:\")\n",
    "missing_info = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'ê²°ì¸¡_ê°œìˆ˜': X_train.isnull().sum().values,\n",
    "    'ê²°ì¸¡_ë¹„ìœ¨(%)': (X_train.isnull().mean() * 100).values\n",
    "}).sort_values('ê²°ì¸¡_ë¹„ìœ¨(%)', ascending=False)\n",
    "print(missing_info)\n",
    "print(f\"\\nì „ì²´ ê²°ì¸¡ ë¹„ìœ¨: {X_train.isnull().mean().mean()*100:.1f}%\")\n",
    "print(f\"Feature ê°œìˆ˜: {X_train.shape[1]}ê°œ\")\n",
    "\n",
    "# ============================================\n",
    "# 2. Pipeline êµ¬ì„± (ê¸°ì¡´ê³¼ ë™ì¼ - ì´ë¯¸ ì˜¬ë°”ë¦„)\n",
    "# ============================================\n",
    "pipeline = ImbPipeline([\n",
    "    ('imputer', SimpleImputer(\n",
    "        strategy='median',\n",
    "        # add_indicator=True # add_indicatorëŠ” 13ë²ˆ ì„¹ì…˜ê³¼ ì—°ë™ë˜ë¯€ë¡œ í•„ìš”ì‹œ ì£¼ì„ í•´ì œ\n",
    "    )),\n",
    "    \n",
    "    ('smote', SMOTE(\n",
    "        random_state=42\n",
    "    )),\n",
    "    \n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary',\n",
    "        device='gpu',\n",
    "        random_state=42,\n",
    "        verbosity=-1,\n",
    "        n_jobs=1\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"\\nâœ… Pipeline êµ¬ì„±:\")\n",
    "print(\"   1. SimpleImputer (median)\")\n",
    "print(\"   2. SMOTE (ì†Œìˆ˜ í´ë˜ìŠ¤ 0 ì¦ê°•)\")\n",
    "print(\"   3. LGBMClassifier (GPU)\")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 3. íŒŒë¼ë¯¸í„° ë¶„í¬ (ìˆ˜ì •ë¨)\n",
    "# ============================================\n",
    "print(f\"\\nì†Œìˆ˜ í´ë˜ìŠ¤(0) ìƒ˜í”Œ ìˆ˜: {minority_count}ê°œ\") # ì˜¬ë°”ë¥¸ ì†Œìˆ˜ ìƒ˜í”Œ ìˆ˜\n",
    "print(f\"ë‹¤ìˆ˜ í´ë˜ìŠ¤(1) ìƒ˜í”Œ ìˆ˜: {majority_count}ê°œ\")\n",
    "\n",
    "# ğŸ”¥ max_k ê³„ì‚° ìˆ˜ì •: ì˜¬ë°”ë¥¸ minority_countë¥¼ ì‚¬ìš©í•´ì•¼ í•¨\n",
    "# SMOTEì˜ k_neighborsëŠ” ì†Œìˆ˜ í´ë˜ìŠ¤ ìƒ˜í”Œ ìˆ˜ë³´ë‹¤ ì‘ì•„ì•¼ í•¨\n",
    "max_k = min(7, minority_count - 1) \n",
    "if max_k < 3:\n",
    "    print(f\"âš ï¸ Â ì†Œìˆ˜ ìƒ˜í”Œ ìˆ˜({minority_count})ê°€ ë„ˆë¬´ ì ì–´ k_neighbors ìµœì†Œê°’(3) í™•ë³´ ë¶ˆê°€.\")\n",
    "    max_k = minority_count - 1 # ìµœì†Œ 1ì´ë¼ë„ í™•ë³´\n",
    "    if max_k < 1: max_k = 1 # këŠ” 1 ì´ìƒì´ì–´ì•¼ í•¨\n",
    "\n",
    "print(f\"SMOTE k_neighbors ìµœëŒ€ê°’ (min(7, {minority_count}-1)): {max_k}\")\n",
    "\n",
    "param_distributions = {\n",
    "    # ğŸ”¥ SMOTE íŒŒë¼ë¯¸í„° - ë” ê³µê²©ì ìœ¼ë¡œ\n",
    "    'smote__sampling_strategy': [0.7, 0.9, 1.0],   # ë†’ì€ ë¹„ìœ¨ë¡œ ì¦ê°•\n",
    "    'smote__k_neighbors': randint(3, max_k + 1), # 3ë¶€í„° max_k (í¬í•¨)\n",
    "    \n",
    "    # ğŸ”¥ LightGBM íŒŒë¼ë¯¸í„° - ì†Œìˆ˜ í´ë˜ìŠ¤ ë¯¼ê°ë„ í–¥ìƒ\n",
    "    'model__n_estimators': randint(300, 1000),      # ë” ë§ì€ íŠ¸ë¦¬\n",
    "    'model__learning_rate': uniform(0.005, 0.045), # ë” ì‘ì€ í•™ìŠµë¥  (0.005~0.05)\n",
    "    'model__max_depth': randint(3, 8),\n",
    "    'model__num_leaves': randint(15, 80),\n",
    "    'model__min_child_samples': randint(5, 50),     # ğŸ”¥ ë” ì‘ê²Œ (ì†Œìˆ˜ í´ë˜ìŠ¤ ë¯¼ê°)\n",
    "    'model__subsample': uniform(0.6, 0.4),\n",
    "    'model__colsample_bytree': uniform(0.6, 0.4),\n",
    "    'model__min_child_weight': [1e-5, 1e-4, 1e-3, 1e-2], # ğŸ”¥ ë” ì‘ê²Œ\n",
    "    'model__reg_alpha': uniform(0, 0.5),            # L1 ì •ê·œí™” ì¤„ì„\n",
    "    'model__reg_lambda': uniform(0, 0.5),           # L2 ì •ê·œí™” ì¤„ì„\n",
    "    'model__scale_pos_weight': uniform(0.5, 2.5)    # ğŸ”¥ ì¶”ê°€: 0.5~3.0\n",
    "}\n",
    "\n",
    "# (ì´í›„ 4ë²ˆ ~ 16ë²ˆ ì„¹ì…˜ì€ ê¸°ì¡´ ìŠ¤í¬ë¦½íŠ¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤.)\n",
    "# ============================================\n",
    "# 4. Scoring ì„¤ì • (ğŸ”¥ f1_macro ë©”ì¸)\n",
    "# ============================================\n",
    "from sklearn.metrics import make_scorer, recall_score, precision_score, f1_score, fbeta_score, average_precision_score\n",
    "\n",
    "# ğŸ”¥ F2 score: Recallì„ Precisionë³´ë‹¤ 2ë°° ì¤‘ìš”í•˜ê²Œ\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2, pos_label=0, zero_division=0)\n",
    "\n",
    "scoring = {\n",
    "    'recall': make_scorer(recall_score, pos_label=0),  # ğŸ”¥ ë©”ì¸ ëª©í‘œ\n",
    "    'f2': f2_scorer,                                    # Recall ê°€ì¤‘\n",
    "    'precision': make_scorer(precision_score, pos_label=0, zero_division=0),\n",
    "    'f1': make_scorer(f1_score, pos_label=0, zero_division=0),\n",
    "    'pr_auc': make_scorer(average_precision_score, needs_proba=True, pos_label=0),\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 5. Stratified K-Fold\n",
    "# ============================================\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "n_folds = 5\n",
    "n_iter = 150\n",
    "\n",
    "print(f\"\\nêµì°¨ê²€ì¦ Folds: {n_folds}\")\n",
    "print(f\"ëœë¤ ìƒ˜í”Œë§ ì¡°í•© ìˆ˜: {n_iter}ê°œ\")\n",
    "print(f\"ì´ Fits: {n_iter} Ã— {n_folds} = {n_iter * n_folds}\")\n",
    "\n",
    "# ============================================\n",
    "# 6. ì˜ˆìƒ ì‹œê°„ ê³„ì‚°\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"â±ï¸  ì˜ˆìƒ ì‹œê°„ ê³„ì‚° ì¤‘...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sample_pipeline = ImbPipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median', add_indicator=True)),\n",
    "    ('smote', SMOTE(random_state=42, sampling_strategy=0.5, k_neighbors=3)),\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary',\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        num_leaves=31,\n",
    "        device='gpu',\n",
    "        random_state=42,\n",
    "        verbosity=-1,\n",
    "        n_jobs=1\n",
    "    ))\n",
    "])\n",
    "\n",
    "start_time = time.time()\n",
    "_ = cross_val_score(\n",
    "    sample_pipeline, X_train, y_train,\n",
    "    cv=3,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=1\n",
    ")\n",
    "sample_time = time.time() - start_time\n",
    "\n",
    "n_cores = os.cpu_count() or 4\n",
    "estimated_per_combination = sample_time / 3 * n_folds\n",
    "estimated_total_sequential = estimated_per_combination * n_iter\n",
    "parallel_factor = min(2.5, n_cores / 2)\n",
    "estimated_parallel = estimated_total_sequential / parallel_factor\n",
    "\n",
    "print(f\"ìƒ˜í”Œ Pipeline ì†Œìš”: {sample_time:.1f}ì´ˆ (3-fold)\")\n",
    "print(f\"ì¡°í•©ë‹¹ ì˜ˆìƒ ì‹œê°„: {estimated_per_combination:.1f}ì´ˆ (5-fold)\")\n",
    "print(f\"ì˜ˆìƒ ì´ ì‹œê°„ (ìˆœì°¨): {estimated_total_sequential/60:.1f}ë¶„\")\n",
    "print(f\"ì˜ˆìƒ ì´ ì‹œê°„ (ë³‘ë ¬, íš¨ìœ¨ {parallel_factor:.1f}x): {estimated_parallel/60:.1f}ë¶„\")\n",
    "\n",
    "estimated_finish = time.time() + estimated_parallel\n",
    "print(f\"\\nğŸ’¡ ì˜ˆìƒ ì™„ë£Œ ì‹œê°: {time.strftime('%H:%M:%S', time.localtime(estimated_finish))}\")\n",
    "\n",
    "if estimated_parallel < 1800:\n",
    "    print(f\"\\nâœ… ì˜ˆìƒ ì‹œê°„ì´ ì ì ˆí•©ë‹ˆë‹¤ (~{estimated_parallel/60:.0f}ë¶„)\")\n",
    "elif estimated_parallel < 3600:\n",
    "    print(f\"\\nâš ï¸  ì˜ˆìƒ ì‹œê°„ì´ ë‹¤ì†Œ ê¹ë‹ˆë‹¤ (~{estimated_parallel/60:.0f}ë¶„)\")\n",
    "    print(\"   ì»¤í”¼ í•œ ì” í•˜ê³  ì˜¤ì‹œë©´ ë©ë‹ˆë‹¤ â˜•\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  ì˜ˆìƒ ì‹œê°„ì´ ê¹ë‹ˆë‹¤ (~{estimated_parallel/60:.0f}ë¶„)\")\n",
    "    print(f\"   n_iterë¥¼ ì¤„ì´ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”\")\n",
    "\n",
    "# ============================================\n",
    "# 7. RandomizedSearchCV ì‹¤í–‰\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸš€ RandomizedSearchCV ì‹œì‘!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lgbm_random = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=n_iter,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    refit='recall',  # ğŸ”¥ F1-macro ê¸°ì¤€ìœ¼ë¡œ ìµœì  ëª¨ë¸ ì„ íƒ\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    # return_train_score=False\n",
    ")\n",
    "\n",
    "start_actual = time.time()\n",
    "lgbm_random.fit(X_train, y_train)\n",
    "actual_time = time.time() - start_actual\n",
    "# ============================================\n",
    "# 8. ê²°ê³¼ ì¶œë ¥\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… ì™„ë£Œ!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"â±ï¸  ì‹¤ì œ ì†Œìš” ì‹œê°„: {actual_time/60:.1f}ë¶„ ({actual_time:.0f}ì´ˆ)\")\n",
    "print(f\"   ì˜ˆìƒ ëŒ€ë¹„: {actual_time/estimated_parallel*100:.0f}%\")\n",
    "\n",
    "if actual_time < estimated_parallel * 0.8:\n",
    "    print(\"   â†’ ì˜ˆìƒë³´ë‹¤ ë¹ ë¦„! ë³‘ë ¬ ì²˜ë¦¬ íš¨ìœ¨ ì¢‹ìŒ âœ¨\")\n",
    "elif actual_time > estimated_parallel * 1.2:\n",
    "    print(\"   â†’ ì˜ˆìƒë³´ë‹¤ ëŠë¦¼. ì‹œìŠ¤í…œ ë¶€í•˜ í™•ì¸ í•„ìš”\")\n",
    "else:\n",
    "    print(\"   â†’ ì˜ˆìƒ ì‹œê°„ê³¼ ìœ ì‚¬í•¨\")\n",
    "\n",
    "print(f\"\\nğŸ† ìµœê³  Recall (CV): {lgbm_random.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ“‹ ìµœì  íŒŒë¼ë¯¸í„°:\")\n",
    "for key, value in sorted(lgbm_random.best_params_.items()):\n",
    "    if isinstance(value, float):\n",
    "        print(f\"   {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d3bdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 9. ì „ì²´ ê²°ê³¼ ë¹„êµ\n",
    "# ============================================\n",
    "results_df = pd.DataFrame(lgbm_random.cv_results_)\n",
    "\n",
    "comparison_cols = [\n",
    "    'rank_test_recall',\n",
    "    'mean_test_recall',\n",
    "    'mean_test_f2',\n",
    "    'mean_test_precision',\n",
    "    'mean_test_f1',\n",
    "    'mean_test_pr_auc',\n",
    "    'mean_test_roc_auc',\n",
    "    'params'\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ìƒìœ„ 10ê°œ íŒŒë¼ë¯¸í„° ì¡°í•© (Recall ê¸°ì¤€)\")\n",
    "print(\"=\"*60)\n",
    "top_10 = results_df[comparison_cols].sort_values('rank_test_recall').head(10)\n",
    "\n",
    "for idx, row in top_10.iterrows():\n",
    "    print(f\"\\n#{int(row['rank_test_recall'])} - Recall: {row['mean_test_recall']:.4f}\")\n",
    "    print(f\"   F2: {row['mean_test_f2']:.3f} | Precision: {row['mean_test_precision']:.3f} | F1: {row['mean_test_f1']:.3f}\")\n",
    "    \n",
    "    params = row['params']\n",
    "    print(f\"   SMOTE: strategy={params.get('smote__sampling_strategy', 'N/A')}, k={params.get('smote__k_neighbors', 'N/A')}\")\n",
    "    print(f\"   Model: lr={params.get('model__learning_rate', 0):.4f}, depth={params.get('model__max_depth', 0)}, leaves={params.get('model__num_leaves', 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacdcf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 10. SMOTE íš¨ê³¼ ë¶„ì„\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”¬ SMOTE íš¨ê³¼ ë¶„ì„\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_sampling = lgbm_random.best_params_.get('smote__sampling_strategy', 1.0)\n",
    "best_k = lgbm_random.best_params_.get('smote__k_neighbors', 5)\n",
    "\n",
    "minority_after_smote = int(majority_count * best_sampling)\n",
    "\n",
    "print(f\"ì›ë³¸ ë°ì´í„°:\")\n",
    "print(f\"   1 (1ë“±ê¸‰, ë‹¤ìˆ˜): {majority_count}ê°œ\")\n",
    "print(f\"   0 (ê·¸ì™¸, ì†Œìˆ˜): {minority_count}ê°œ\")\n",
    "print(f\"   ë¹„ìœ¨: {majority_count/minority_count:.1f}:1\")\n",
    "\n",
    "print(f\"\\nSMOTE ì ìš© í›„ (ìµœì  íŒŒë¼ë¯¸í„°):\")\n",
    "print(f\"   sampling_strategy: {best_sampling}\")\n",
    "print(f\"   k_neighbors: {best_k}\")\n",
    "print(f\"   1 (1ë“±ê¸‰): {majority_count}ê°œ (ìœ ì§€)\")\n",
    "print(f\"   0 (ê·¸ì™¸): ~{minority_after_smote}ê°œ (ì¦ê°•)\")\n",
    "print(f\"   ë¹„ìœ¨: ~{1/best_sampling:.1f}:1\")\n",
    "print(f\"   ì¦ê°•ëœ ìƒ˜í”Œ: {minority_after_smote - minority_count}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc8e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 11. í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ§ª í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_model = lgbm_random.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "y_pred_proba_minority = y_pred_proba[:, 0]\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['0 (ê·¸ì™¸, ì†Œìˆ˜)', '1 (1ë“±ê¸‰, ë‹¤ìˆ˜)']))\n",
    "\n",
    "print(\"\\ní˜¼ë™ í–‰ë ¬:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index=['ì‹¤ì œ_0 (ê·¸ì™¸)', 'ì‹¤ì œ_1 (1ë“±ê¸‰)'],\n",
    "                     columns=['ì˜ˆì¸¡_0 (ê·¸ì™¸)', 'ì˜ˆì¸¡_1 (1ë“±ê¸‰)'])\n",
    "print(cm_df)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"\\nğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„ (ì†Œìˆ˜ í´ë˜ìŠ¤=0=ê·¸ì™¸ ê¸°ì¤€):\")\n",
    "print(f\"   âœ… ì •í™•í•œ ë¶„ë¥˜: {tn + tp}ê°œ ({(tn+tp)/len(y_test)*100:.1f}%)\")\n",
    "print(f\"   âš ï¸  ì˜¤íƒ (1â†’0): {fp}ê°œ â†’ 1ë“±ê¸‰ì„ ê·¸ì™¸ë¡œ ì˜¤íŒ (ì¬ê²€ì‚¬ í•„ìš”)\")\n",
    "print(f\"   ğŸš¨ ë¯¸íƒ (0â†’1): {fn}ê°œ â†’ ê·¸ì™¸ë¥¼ 1ë“±ê¸‰ìœ¼ë¡œ ì˜¤íŒ (ì¹˜ëª…ì !)\")\n",
    "\n",
    "if tn + fn > 0:\n",
    "    recall_pct = tn/(tn+fn)*100\n",
    "    print(f\"   ğŸ“Š ì†Œìˆ˜ í´ë˜ìŠ¤(0) Recall: {recall_pct:.1f}% (ê·¸ì™¸ {tn+fn}ê°œ ì¤‘ {tn}ê°œ ê²€ì¶œ)\")\n",
    "    print(f\"      â†’ ì´ì „ 14% ëŒ€ë¹„ ê°œì„ : {recall_pct - 14:.1f}%p âœ¨\")\n",
    "else:\n",
    "    print(f\"   ğŸ“Š ì†Œìˆ˜ í´ë˜ìŠ¤(0) Recall: N/A\")\n",
    "\n",
    "if tn + fp > 0:\n",
    "    precision_pct = tn/(tn+fp)*100\n",
    "    print(f\"   ğŸ“Š ì†Œìˆ˜ í´ë˜ìŠ¤(0) Precision: {precision_pct:.1f}% (ê·¸ì™¸ íŒì • {tn+fp}ê°œ ì¤‘ {tn}ê°œ ì •ë‹µ)\")\n",
    "else:\n",
    "    print(f\"   ğŸ“Š ì†Œìˆ˜ í´ë˜ìŠ¤(0) Precision: N/A\")\n",
    "\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba_minority)\n",
    "print(f\"   ğŸ“Š ROC-AUC: {test_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea202ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 12. ğŸ”¥ ì„ê³„ê°’ ì¡°ì •ìœ¼ë¡œ ì¶”ê°€ ê°œì„ \n",
    "# ============================================\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred_proba_minority, pos_label=0)\n",
    "\n",
    "# Recall 80% ë³´ì¥\n",
    "target_recall = 0.80\n",
    "idx = np.where(recalls >= target_recall)[0]\n",
    "\n",
    "if len(idx) > 0:\n",
    "    best_idx = idx[np.argmax(precisions[idx])]\n",
    "    optimal_threshold = thresholds[best_idx]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ğŸ¯ Recall {target_recall*100}% ë³´ì¥ ì‹œ ìµœì  ì„ê³„ê°’\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ìµœì  ì„ê³„ê°’: {optimal_threshold:.3f} (ê¸°ë³¸ê°’ 0.5)\")\n",
    "    print(f\"Precision: {precisions[best_idx]:.3f}\")\n",
    "    print(f\"Recall: {recalls[best_idx]:.3f}\")\n",
    "    \n",
    "    y_pred_adjusted = np.where(y_pred_proba_minority >= optimal_threshold, 0, 1)\n",
    "    \n",
    "    cm_adj = confusion_matrix(y_test, y_pred_adjusted)\n",
    "    tn2, fp2, fn2, tp2 = cm_adj.ravel()\n",
    "    \n",
    "    print(f\"\\nì¡°ì • íš¨ê³¼:\")\n",
    "    print(f\"   ë¯¸íƒ(FN) ê°ì†Œ: {fn} â†’ {fn2} (ê°œì„ : {fn-fn2}ê°œ)\")\n",
    "    print(f\"   ì˜¤íƒ(FP) ì¦ê°€: {fp} â†’ {fp2} (ì¦ê°€: {fp2-fp}ê°œ)\")\n",
    "    print(f\"   Recall ê°œì„ : {tn/(tn+fn)*100:.1f}% â†’ {tn2/(tn2+fn2)*100:.1f}%\")\n",
    "    \n",
    "    if fn > fn2:\n",
    "        print(f\"   ğŸ’¡ ê·¸ì™¸ë¥¼ 1ë“±ê¸‰ìœ¼ë¡œ ì˜¤íŒí•˜ëŠ” ì¹˜ëª…ì  ì˜¤ë¥˜ {fn-fn2}ê°œ ê°ì†Œ!\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  Recall {target_recall*100}% ë‹¬ì„± ë¶ˆê°€ (ìµœëŒ€ Recall: {recalls.max():.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2036fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 13. ë³€ìˆ˜ ì¤‘ìš”ë„ í™•ì¸\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ë³€ìˆ˜ ì¤‘ìš”ë„ Top 10\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_model = best_model.named_steps['model']\n",
    "feature_names = list(X_train.columns)\n",
    "\n",
    "imputer = best_model.named_steps['imputer']\n",
    "if imputer.add_indicator:\n",
    "    missing_features = X_train.columns[X_train.isnull().any()].tolist()\n",
    "    for col in missing_features:\n",
    "        feature_names.append(f\"{col}_ê²°ì¸¡ì§€í‘œ\")\n",
    "\n",
    "n_features_used = len(final_model.feature_importances_)\n",
    "feature_names = feature_names[:n_features_used]\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(importance_df.head(10).to_string(index=False))\n",
    "\n",
    "missing_indicators = importance_df[importance_df['feature'].str.contains('ê²°ì¸¡ì§€í‘œ', na=False)]\n",
    "if len(missing_indicators) > 0:\n",
    "    print(\"\\nğŸ’¡ ê²°ì¸¡ ì§€í‘œ ë³€ìˆ˜ ì¤‘ìš”ë„:\")\n",
    "    print(missing_indicators.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6043ed8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 14. êµì°¨ê²€ì¦ vs í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ë¹„êµ\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ: êµì°¨ê²€ì¦ vs í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_metrics = {\n",
    "    'Recall': recall_score(y_test, y_pred, pos_label=0),\n",
    "    'F2': fbeta_score(y_test, y_pred, beta=2, pos_label=0),\n",
    "    'Precision': precision_score(y_test, y_pred, pos_label=0, zero_division=0),\n",
    "    'F1': f1_score(y_test, y_pred, pos_label=0, zero_division=0),\n",
    "    'PR-AUC': average_precision_score(y_test, y_pred_proba_minority, pos_label=0),\n",
    "    'ROC-AUC': test_roc_auc\n",
    "}\n",
    "\n",
    "print(f\"{'ì§€í‘œ':<15} {'êµì°¨ê²€ì¦ (CV)':<20} {'í…ŒìŠ¤íŠ¸':<15} {'ì°¨ì´':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for metric in ['Recall', 'F2', 'Precision', 'F1', 'PR-AUC', 'ROC-AUC']:\n",
    "    cv_key = metric.lower().replace('-', '_')\n",
    "    cv_score = results_df.loc[results_df['rank_test_recall'] == 1, f'mean_test_{cv_key}'].values[0]\n",
    "    test_score = test_metrics[metric]\n",
    "    diff = test_score - cv_score\n",
    "    \n",
    "    diff_str = f\"{diff:+.4f}\"\n",
    "    if abs(diff) > 0.05:\n",
    "        diff_str += \" âš ï¸\"\n",
    "    \n",
    "    print(f\"{metric:<15} {cv_score:<20.4f} {test_score:<15.4f} {diff_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd9033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 15. ìµœì¢… ìš”ì•½\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“ ìµœì¢… ìš”ì•½ (Recall ê°œì„ )\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ… ìµœì  ëª¨ë¸ Recall (CV): {lgbm_random.best_score_:.4f}\")\n",
    "print(f\"âœ… í…ŒìŠ¤íŠ¸ Recall: {test_metrics['Recall']*100:.1f}%\")\n",
    "print(f\"âœ… í…ŒìŠ¤íŠ¸ Precision: {test_metrics['Precision']*100:.1f}%\")\n",
    "print(f\"âœ… í…ŒìŠ¤íŠ¸ F1: {test_metrics['F1']:.4f}\")\n",
    "print(f\"âœ… ì¹˜ëª…ì  ì˜¤ë¥˜(ë¯¸íƒ): {fn}ê°œ / {tn+fn}ê°œ\")\n",
    "print(f\"â±ï¸  ì´ ì†Œìš” ì‹œê°„: {actual_time/60:.1f}ë¶„\")\n",
    "\n",
    "print(\"\\nğŸ¯ ê°œì„  íš¨ê³¼:\")\n",
    "print(f\"   - Recall: 14.0% â†’ {test_metrics['Recall']*100:.1f}% (â†‘{test_metrics['Recall']*100-14:.1f}%p)\")\n",
    "print(f\"   - ë¯¸íƒ ê°ì†Œ: {int(4698*0.86)} â†’ {fn}ê°œ (â†“{int(4698*0.86)-fn}ê°œ)\")\n",
    "\n",
    "print(\"\\nğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸:\")\n",
    "print(f\"   - ê·¸ì™¸(0) {tn+fn}ê°œ ì¤‘ {tn}ê°œ ê²€ì¶œ ({tn/(tn+fn)*100:.1f}%)\")\n",
    "print(f\"   - ë†“ì¹œ ê·¸ì™¸: {fn}ê°œ (ì´ì „ {int(4698*0.86)}ê°œ ëŒ€ë¹„ ëŒ€í­ ê°ì†Œ)\")\n",
    "print(f\"   - ì˜¤íƒ ì¦ê°€: {fp}ê°œ (ì¬ê²€ì‚¬ í•„ìš”í•˜ì§€ë§Œ ê°ìˆ˜ ê°€ëŠ¥)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 16. ëª¨ë¸ + íŒŒë¼ë¯¸í„° ì €ì¥\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ’¾ ëª¨ë¸ ë° íŒŒë¼ë¯¸í„° ì €ì¥\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "save_model = input(\"ëª¨ë¸ì„ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): \")\n",
    "if save_model.lower() == 'y':\n",
    "    import joblib\n",
    "    from datetime import datetime\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    model_filename = MODEL_DIR / f'best_lgbm_recall_optimized_{timestamp}.pkl'\n",
    "    params_filename = MODEL_DIR / f'best_params_recall_{timestamp}.json'\n",
    "    metrics_filename = MODEL_DIR / f'test_metrics_recall_{timestamp}.json'\n",
    "    results_filename = MODEL_DIR / f'cv_results_recall_{timestamp}.csv'\n",
    "    \n",
    "    # 1. ëª¨ë¸ ì €ì¥\n",
    "    joblib.dump(best_model, model_filename)\n",
    "    print(f\"âœ… ëª¨ë¸ ì €ì¥: {model_filename}\")\n",
    "    \n",
    "    # 2. íŒŒë¼ë¯¸í„° ì €ì¥\n",
    "    best_params_serializable = {}\n",
    "    for key, value in lgbm_random.best_params_.items():\n",
    "        if isinstance(value, (np.integer, np.floating)):\n",
    "            best_params_serializable[key] = float(value) if isinstance(value, np.floating) else int(value)\n",
    "        else:\n",
    "            best_params_serializable[key] = value\n",
    "    \n",
    "    params_info = {\n",
    "        'best_params': best_params_serializable,\n",
    "        'best_recall_score': float(lgbm_random.best_score_),\n",
    "        'optimization_target': 'recall',\n",
    "        'cv_folds': n_folds,\n",
    "        'n_iter': n_iter,\n",
    "        'timestamp': timestamp,\n",
    "        'minority_count': int(minority_count),\n",
    "        'majority_count': int(majority_count),\n",
    "        'smote_sampling_strategy': float(best_sampling),\n",
    "        'smote_k_neighbors': int(best_k)\n",
    "    }\n",
    "    \n",
    "    with open(params_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(params_info, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"âœ… íŒŒë¼ë¯¸í„° ì €ì¥: {params_filename}\")\n",
    "    \n",
    "    # 3. í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ì €ì¥\n",
    "    test_metrics_serializable = {\n",
    "        key: float(value) if isinstance(value, (np.floating, np.integer)) else value\n",
    "        for key, value in test_metrics.items()\n",
    "    }\n",
    "    \n",
    "    metrics_info = {\n",
    "        'test_metrics': test_metrics_serializable,\n",
    "        'confusion_matrix': {\n",
    "            'tn': int(tn),\n",
    "            'fp': int(fp),\n",
    "            'fn': int(fn),\n",
    "            'tp': int(tp)\n",
    "        },\n",
    "        'business_interpretation': {\n",
    "            'total_minority': int(tn + fn),\n",
    "            'detected_minority': int(tn),\n",
    "            'missed_minority': int(fn),\n",
    "            'recall_percentage': float(tn/(tn+fn)*100),\n",
    "            'false_alarms': int(fp)\n",
    "        },\n",
    "        'improvement': {\n",
    "            'baseline_recall': 14.0,\n",
    "            'new_recall': float(test_metrics['Recall']*100),\n",
    "            'improvement_pp': float(test_metrics['Recall']*100 - 14.0)\n",
    "        },\n",
    "        'timestamp': timestamp\n",
    "    }\n",
    "    \n",
    "    with open(metrics_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metrics_info, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"âœ… í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ì €ì¥: {metrics_filename}\")\n",
    "    \n",
    "    # 4. CV ê²°ê³¼ ì €ì¥\n",
    "    results_df.to_csv(results_filename, index=False, encoding='utf-8')\n",
    "    print(f\"âœ… CV ê²°ê³¼ ì €ì¥: {results_filename}\")\n",
    "    \n",
    "    print(\"\\nğŸ“¦ ì €ì¥ëœ íŒŒì¼ ìš”ì•½:\")\n",
    "    print(f\"1. ëª¨ë¸: {model_filename.name}\")\n",
    "    print(f\"2. íŒŒë¼ë¯¸í„°: {params_filename.name}\")\n",
    "    print(f\"3. ì„±ëŠ¥: {metrics_filename.name}\")\n",
    "    print(f\"4. CVê²°ê³¼: {results_filename.name}\")\n",
    "    \n",
    "else:\n",
    "    print(\"ëª¨ë¸ ì €ì¥ ìƒëµ\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ceb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'best_lgbm_smote_random',\n",
    "    'best_lgbm_smote_20251106_155837',\n",
    "    'best_lgbm_recall_optimized_20251106_162548'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caead454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "loaded_model = joblib.load(MODEL_DIR / 'best_lgbm_recall_optimized_20251106_162548.pkl')\n",
    "predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df76826",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647723e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.223     0.390     0.284      4698\n",
      "           1      0.857     0.729     0.788     23600\n",
      "\n",
      "    accuracy                          0.673     28298\n",
      "   macro avg      0.540     0.560     0.536     28298\n",
      "weighted avg      0.752     0.673     0.704     28298\n",
      "\n",
      "\n",
      "Balanced Accuracy (Test Set): 0.560\n",
      "ROC-AUC (OvO, macro, Test Set): 0.598\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ì…‹ ì„±ëŠ¥ í‰ê°€\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_prob = loaded_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "# Balanced Accuracy\n",
    "bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nBalanced Accuracy (Test Set): {bal_acc:.3f}\")\n",
    "\n",
    "# ROC-AUC (OvO, macro)\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y_train))\n",
    "roc_auc_ovo = roc_auc_score(y_test_bin, y_prob, average='macro')\n",
    "print(f\"ROC-AUC (OvO, macro, Test Set): {roc_auc_ovo:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
