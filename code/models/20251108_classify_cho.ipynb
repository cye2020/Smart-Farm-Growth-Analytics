{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28021e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/yeeun/anaconda3/envs/smartfarm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 1. í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import platform\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "# 2. ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬ \n",
    "\n",
    "# 2-1. ì‹œê°í™”\n",
    "import plotly.express as px\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "\n",
    "# 2-2. \n",
    "import shap\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, make_scorer, recall_score, \n",
    "    precision_score, f1_score, fbeta_score, average_precision_score, balanced_accuracy_score, precision_recall_fscore_support\n",
    ")\n",
    "from scipy.stats import uniform, randint\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from utils import DATA_DIR, MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03e26762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "if platform.system() == 'Windows':\n",
    "    plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "elif platform.system() == 'Darwin':  # macOS\n",
    "    plt.rcParams['font.family'] = 'AppleGothic'\n",
    "else:  # Linux\n",
    "    plt.rcParams['font.family'] = 'NanumGothic'\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "# í°íŠ¸ ê°œì¸ ê²½ë¡œì— ë§ì¶°ì„œ ë³€ê²½\n",
    "# FONT_DIR = Path(\"/path/to/fonts\")\n",
    "# font_path = FONT_DIR / 'FREESENTATION-6SEMIBOLD.ttf'\n",
    "# prop = fm.FontProperties(fname=font_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced663af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ë†ì¥ì•„ì´ë””",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ê°œì²´ë²ˆí˜¸",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ê²€ì •ì¼ì",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "ëˆ„ì ì°©ìœ ì¼(ì—°ê³„)",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ë¬´ì§€ê³ í˜•ë¶„",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ìš°ìœ ë‚´ìš”ì†Œíƒœì§ˆì†Œ",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "305ì¼ìœ ëŸ‰",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "305ì¼ë¬´ì§€ê³ í˜•ë¶„",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ì „ì‚°ì°¨ë¹„ìœ ì§€ì†ì„±",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ì „ì‚°ì°¨ê±´ìœ ì „ìœ ëŸ‰",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ì‚°ì°¨",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ë†í›„ì‚¬ë£Œë¹„(ì—°ê³„)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ë†í›„ì‚¬ë£Œê¸‰ì—¬ëŸ‰(ì—°ê³„)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ê³µíƒœì¼ìˆ˜",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ë¹„ìœ ë‹¨ê³„",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ê³„ì ˆ",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ë†ì¥êµ¬ë¶„",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ì •ì•¡ì½”ë“œë¶„ë¥˜",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ê°€ê²©",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ê°€ê²©ë¯¸ë‹¬",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ë¶„ë§Œê°„ê²©",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ë¶„ë§Œì›”ë ¹",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "896addaa-02d2-420b-9627-5257ae6164f4",
       "rows": [
        [
         "0",
         "20249",
         "20120709020022",
         "2020-01-11 00:00:00",
         "154",
         "0",
         "1",
         "9714.0",
         "805.0",
         "50.5",
         "16.1",
         "6",
         "0.0",
         "0.0",
         null,
         "1",
         "4",
         "1",
         null,
         "1056.34",
         "0",
         null,
         "85"
        ],
        [
         "1",
         "20249",
         "20120504020095",
         "2020-01-11 00:00:00",
         "52",
         "0",
         "1",
         null,
         null,
         "68.8",
         "22.6",
         "5",
         "0.0",
         "0.0",
         null,
         "1",
         "4",
         "1",
         null,
         "1056.34",
         "0",
         null,
         "90"
        ],
        [
         "2",
         "20249",
         "20111008020210",
         "2020-01-11 00:00:00",
         "115",
         "0",
         "1",
         "11008.0",
         "971.0",
         "54.1",
         "24.5",
         "5",
         "0.0",
         "0.0",
         null,
         "2",
         "4",
         "1",
         null,
         "1060.34",
         "0",
         null,
         "95"
        ],
        [
         "3",
         "20249",
         "20121014020049",
         "2020-01-11 00:00:00",
         "290",
         "1",
         "1",
         "11318.0",
         "1011.0",
         "58.6",
         "37.8",
         "5",
         "0.0",
         "0.0",
         "224.0",
         "3",
         "4",
         "1",
         "7HO",
         "1062.31",
         "0",
         null,
         "77"
        ],
        [
         "4",
         "20249",
         "20130812020216",
         "2020-01-11 00:00:00",
         "100",
         "0",
         "1",
         "11324.0",
         "957.0",
         "68.1",
         "20.5",
         "4",
         "0.0",
         "0.0",
         null,
         "2",
         "4",
         "1",
         null,
         "1056.34",
         "0",
         null,
         "75"
        ]
       ],
       "shape": {
        "columns": 22,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ë†ì¥ì•„ì´ë””</th>\n",
       "      <th>ê°œì²´ë²ˆí˜¸</th>\n",
       "      <th>ê²€ì •ì¼ì</th>\n",
       "      <th>ëˆ„ì ì°©ìœ ì¼(ì—°ê³„)</th>\n",
       "      <th>ë¬´ì§€ê³ í˜•ë¶„</th>\n",
       "      <th>ìš°ìœ ë‚´ìš”ì†Œíƒœì§ˆì†Œ</th>\n",
       "      <th>305ì¼ìœ ëŸ‰</th>\n",
       "      <th>305ì¼ë¬´ì§€ê³ í˜•ë¶„</th>\n",
       "      <th>ì „ì‚°ì°¨ë¹„ìœ ì§€ì†ì„±</th>\n",
       "      <th>ì „ì‚°ì°¨ê±´ìœ ì „ìœ ëŸ‰</th>\n",
       "      <th>...</th>\n",
       "      <th>ë†í›„ì‚¬ë£Œê¸‰ì—¬ëŸ‰(ì—°ê³„)</th>\n",
       "      <th>ê³µíƒœì¼ìˆ˜</th>\n",
       "      <th>ë¹„ìœ ë‹¨ê³„</th>\n",
       "      <th>ê³„ì ˆ</th>\n",
       "      <th>ë†ì¥êµ¬ë¶„</th>\n",
       "      <th>ì •ì•¡ì½”ë“œë¶„ë¥˜</th>\n",
       "      <th>ê°€ê²©</th>\n",
       "      <th>ê°€ê²©ë¯¸ë‹¬</th>\n",
       "      <th>ë¶„ë§Œê°„ê²©</th>\n",
       "      <th>ë¶„ë§Œì›”ë ¹</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20249</td>\n",
       "      <td>20120709020022</td>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9714.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>50.5</td>\n",
       "      <td>16.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1056.34</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20249</td>\n",
       "      <td>20120504020095</td>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.8</td>\n",
       "      <td>22.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1056.34</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20249</td>\n",
       "      <td>20111008020210</td>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11008.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>54.1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1060.34</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20249</td>\n",
       "      <td>20121014020049</td>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>290</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11318.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>58.6</td>\n",
       "      <td>37.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7HO</td>\n",
       "      <td>1062.31</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20249</td>\n",
       "      <td>20130812020216</td>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11324.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>68.1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1056.34</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ë†ì¥ì•„ì´ë””            ê°œì²´ë²ˆí˜¸       ê²€ì •ì¼ì  ëˆ„ì ì°©ìœ ì¼(ì—°ê³„)  ë¬´ì§€ê³ í˜•ë¶„  ìš°ìœ ë‚´ìš”ì†Œíƒœì§ˆì†Œ   305ì¼ìœ ëŸ‰  \\\n",
       "0  20249  20120709020022 2020-01-11        154      0         1   9714.0   \n",
       "1  20249  20120504020095 2020-01-11         52      0         1      NaN   \n",
       "2  20249  20111008020210 2020-01-11        115      0         1  11008.0   \n",
       "3  20249  20121014020049 2020-01-11        290      1         1  11318.0   \n",
       "4  20249  20130812020216 2020-01-11        100      0         1  11324.0   \n",
       "\n",
       "   305ì¼ë¬´ì§€ê³ í˜•ë¶„  ì „ì‚°ì°¨ë¹„ìœ ì§€ì†ì„±  ì „ì‚°ì°¨ê±´ìœ ì „ìœ ëŸ‰  ...  ë†í›„ì‚¬ë£Œê¸‰ì—¬ëŸ‰(ì—°ê³„)   ê³µíƒœì¼ìˆ˜  ë¹„ìœ ë‹¨ê³„  ê³„ì ˆ  ë†ì¥êµ¬ë¶„  \\\n",
       "0      805.0      50.5      16.1  ...          0.0    NaN     1   4     1   \n",
       "1        NaN      68.8      22.6  ...          0.0    NaN     1   4     1   \n",
       "2      971.0      54.1      24.5  ...          0.0    NaN     2   4     1   \n",
       "3     1011.0      58.6      37.8  ...          0.0  224.0     3   4     1   \n",
       "4      957.0      68.1      20.5  ...          0.0    NaN     2   4     1   \n",
       "\n",
       "   ì •ì•¡ì½”ë“œë¶„ë¥˜       ê°€ê²© ê°€ê²©ë¯¸ë‹¬  ë¶„ë§Œê°„ê²©  ë¶„ë§Œì›”ë ¹  \n",
       "0     NaN  1056.34    0   NaN    85  \n",
       "1     NaN  1056.34    0   NaN    90  \n",
       "2     NaN  1060.34    0   NaN    95  \n",
       "3     7HO  1062.31    0   NaN    77  \n",
       "4     NaN  1056.34    0   NaN    75  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_kwargs = {\n",
    "    'parse_dates': ['ê²€ì •ì¼ì'],\n",
    "    'date_format': '%Y-%m-%d'\n",
    "}\n",
    "\n",
    "milk: pd.DataFrame = pd.read_csv(DATA_DIR /'interim' / 'milk.csv', **pandas_kwargs)\n",
    "milk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "878e8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = milk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4083ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['ì „ì‚°ì°¨ê±´ìœ ì „ìœ ëŸ‰', 'ì‚°ì°¨', 'ë†í›„ì‚¬ë£Œê¸‰ì—¬ëŸ‰(ì—°ê³„)', 'ê³µíƒœì¼ìˆ˜', 'ê³„ì ˆ', 'ë†ì¥êµ¬ë¶„', 'ì •ì•¡ì½”ë“œë¶„ë¥˜','ë¶„ë§Œê°„ê²©']\n",
    "\n",
    "target = 'ê°€ê²©ë¯¸ë‹¬'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2824ebb",
   "metadata": {},
   "source": [
    "## ë²”ì£¼í˜• ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e745b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['ì •ì•¡ì½”ë“œë¶„ë¥˜']\n",
    "\n",
    "for categorical_feature in categorical_features:\n",
    "    df[categorical_feature] = df[categorical_feature].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a9efc8",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51da92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['ê²€ì •ì¼ì'].dt.year == 2020]\n",
    "test = df[df['ê²€ì •ì¼ì'].dt.year == 2021]\n",
    "\n",
    "X_train, X_test = train[features], test[features]\n",
    "y_train, y_test = train[target], test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91a8c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„\n",
      "============================================================\n",
      "ê°€ê²©ë¯¸ë‹¬\n",
      "0    16343\n",
      "1     1794\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ë¹„ìœ¨:\n",
      "ê°€ê²©ë¯¸ë‹¬\n",
      "0    0.901086\n",
      "1    0.098914\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "í´ë˜ìŠ¤ êµ¬ì„±:\n",
      "   0 (ì¼ë°˜ê°€, ë‹¤ìˆ˜): 16343ê°œ (90.1%)\n",
      "   1 (ê°€ê²©ë¯¸ë‹¬, ì†Œìˆ˜): 1794ê°œ (9.9%)\n",
      "\n",
      "ê³„ì‚°ëœ scale_pos_weight: 9.11\n",
      "   â†’ LightGBMì€ ìë™ìœ¼ë¡œ í´ë˜ìŠ¤ 1(ê°€ê²©ë¯¸ë‹¬)ì— ì´ ê°€ì¤‘ì¹˜ ì ìš©\n",
      "\n",
      "ê²°ì¸¡ì¹˜ í˜„í™©:\n",
      "       Feature  ê²°ì¸¡_ê°œìˆ˜   ê²°ì¸¡_ë¹„ìœ¨(%)\n",
      "7         ë¶„ë§Œê°„ê²©  14401  79.401224\n",
      "6       ì •ì•¡ì½”ë“œë¶„ë¥˜   8907  49.109555\n",
      "3         ê³µíƒœì¼ìˆ˜   8481  46.760765\n",
      "0     ì „ì‚°ì°¨ê±´ìœ ì „ìœ ëŸ‰   7340  40.469758\n",
      "1           ì‚°ì°¨      0   0.000000\n",
      "2  ë†í›„ì‚¬ë£Œê¸‰ì—¬ëŸ‰(ì—°ê³„)      0   0.000000\n",
      "4           ê³„ì ˆ      0   0.000000\n",
      "5         ë†ì¥êµ¬ë¶„      0   0.000000\n",
      "\n",
      "ì „ì²´ ê²°ì¸¡ ë¹„ìœ¨: 27.0%\n",
      "Feature ê°œìˆ˜: 8ê°œ\n",
      "\n",
      "âœ… Pipeline êµ¬ì„±:\n",
      "   1. LGBMClassifier (GPU)\n",
      "      - scale_pos_weight=9.11 (í´ë˜ìŠ¤ 1=ê°€ê²©ë¯¸ë‹¬ ê°€ì¤‘ì¹˜)\n",
      "\n",
      "ì†Œìˆ˜ í´ë˜ìŠ¤(1=ê°€ê²©ë¯¸ë‹¬) ìƒ˜í”Œ ìˆ˜: 1794ê°œ\n",
      "\n",
      "âœ… Scoring ì „ëµ:\n",
      "   ë©”ì¸ ëª©í‘œ: PR_AUC\n",
      "   íƒ€ê¹ƒ: í´ë˜ìŠ¤ 1 (ê°€ê²©ë¯¸ë‹¬) ê²€ì¶œ ìµœì í™”\n",
      "   pos_label: 1 (ê¸°ë³¸ê°’, ìƒëµ ê°€ëŠ¥)\n",
      "\n",
      "êµì°¨ê²€ì¦ Folds: 5\n",
      "ëœë¤ ìƒ˜í”Œë§ ì¡°í•© ìˆ˜: 150ê°œ\n",
      "ì´ Fits: 150 Ã— 5 = 750\n",
      "\n",
      "============================================================\n",
      "ğŸš€ RandomizedSearchCV ì‹œì‘!\n",
      "============================================================\n",
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n",
      "[CV 5/5] END model__colsample_bytree=0.749816047538945, model__learning_rate=0.047782143788446224, model__max_depth=5, model__min_child_samples=12, model__min_child_weight=1e-05, model__n_estimators=320, model__num_leaves=38, model__reg_alpha=0.32544423647442644, model__reg_lambda=0.028205789513550128, model__subsample=0.8887995089067299; f1: (test=0.581) f2: (test=0.400) pr_auc: (test=0.285) precision: (test=0.214) recall: (test=0.510) roc_auc: (test=0.697) total time=  11.4s\n",
      "[CV 4/5] END model__colsample_bytree=0.749816047538945, model__learning_rate=0.047782143788446224, model__max_depth=5, model__min_child_samples=12, model__min_child_weight=1e-05, model__n_estimators=320, model__num_leaves=38, model__reg_alpha=0.32544423647442644, model__reg_lambda=0.028205789513550128, model__subsample=0.8887995089067299; f1: (test=0.621) f2: (test=0.506) pr_auc: (test=0.401) precision: (test=0.262) recall: (test=0.660) roc_auc: (test=0.774) total time=  11.5s\n",
      "[CV 1/5] END model__colsample_bytree=0.749816047538945, model__learning_rate=0.047782143788446224, model__max_depth=5, model__min_child_samples=12, model__min_child_weight=1e-05, model__n_estimators=320, model__num_leaves=38, model__reg_alpha=0.32544423647442644, model__reg_lambda=0.028205789513550128, model__subsample=0.8887995089067299; f1: (test=0.589) f2: (test=0.408) pr_auc: (test=0.291) precision: (test=0.224) recall: (test=0.513) roc_auc: (test=0.700) total time=  11.7s\n",
      "[CV 3/5] END model__colsample_bytree=0.749816047538945, model__learning_rate=0.047782143788446224, model__max_depth=5, model__min_child_samples=12, model__min_child_weight=1e-05, model__n_estimators=320, model__num_leaves=38, model__reg_alpha=0.32544423647442644, model__reg_lambda=0.028205789513550128, model__subsample=0.8887995089067299; f1: (test=0.594) f2: (test=0.436) pr_auc: (test=0.305) precision: (test=0.230) recall: (test=0.561) roc_auc: (test=0.726) total time=  12.1s\n",
      "[CV 2/5] END model__colsample_bytree=0.749816047538945, model__learning_rate=0.047782143788446224, model__max_depth=5, model__min_child_samples=12, model__min_child_weight=1e-05, model__n_estimators=320, model__num_leaves=38, model__reg_alpha=0.32544423647442644, model__reg_lambda=0.028205789513550128, model__subsample=0.8887995089067299; f1: (test=0.606) f2: (test=0.452) pr_auc: (test=0.340) precision: (test=0.244) recall: (test=0.574) roc_auc: (test=0.748) total time=  12.5s\n",
      "[CV 1/5] END model__colsample_bytree=0.8447411578889518, model__learning_rate=0.011277223729341881, model__max_depth=6, model__min_child_samples=20, model__min_child_weight=0.001, model__n_estimators=489, model__num_leaves=76, model__reg_alpha=0.3925879806965068, model__reg_lambda=0.09983689107917987, model__subsample=0.8056937753654446; f1: (test=0.570) f2: (test=0.402) pr_auc: (test=0.272) precision: (test=0.203) recall: (test=0.532) roc_auc: (test=0.703) total time=  27.9s\n",
      "[CV 2/5] END model__colsample_bytree=0.8447411578889518, model__learning_rate=0.011277223729341881, model__max_depth=6, model__min_child_samples=20, model__min_child_weight=0.001, model__n_estimators=489, model__num_leaves=76, model__reg_alpha=0.3925879806965068, model__reg_lambda=0.09983689107917987, model__subsample=0.8056937753654446; f1: (test=0.584) f2: (test=0.440) pr_auc: (test=0.327) precision: (test=0.220) recall: (test=0.588) roc_auc: (test=0.746) total time=  29.0s\n",
      "[CV 1/5] END model__colsample_bytree=0.836965827544817, model__learning_rate=0.007090268572399898, model__max_depth=5, model__min_child_samples=11, model__min_child_weight=1e-05, model__n_estimators=466, model__num_leaves=32, model__reg_alpha=0.4744427686266666, model__reg_lambda=0.4828160165372797, model__subsample=0.9233589392465844; f1: (test=0.560) f2: (test=0.388) pr_auc: (test=0.250) precision: (test=0.192) recall: (test=0.521) roc_auc: (test=0.697) total time=  19.6s\n",
      "[CV 2/5] END model__colsample_bytree=0.836965827544817, model__learning_rate=0.007090268572399898, model__max_depth=5, model__min_child_samples=11, model__min_child_weight=1e-05, model__n_estimators=466, model__num_leaves=32, model__reg_alpha=0.4744427686266666, model__reg_lambda=0.4828160165372797, model__subsample=0.9233589392465844; f1: (test=0.567) f2: (test=0.416) pr_auc: (test=0.276) precision: (test=0.201) recall: (test=0.568) roc_auc: (test=0.725) total time=  19.4s\n",
      "[CV 4/5] END model__colsample_bytree=0.8447411578889518, model__learning_rate=0.011277223729341881, model__max_depth=6, model__min_child_samples=20, model__min_child_weight=0.001, model__n_estimators=489, model__num_leaves=76, model__reg_alpha=0.3925879806965068, model__reg_lambda=0.09983689107917987, model__subsample=0.8056937753654446; f1: (test=0.598) f2: (test=0.476) pr_auc: (test=0.370) precision: (test=0.235) recall: (test=0.641) roc_auc: (test=0.767) total time=  27.8s\n",
      "[CV 5/5] END model__colsample_bytree=0.8447411578889518, model__learning_rate=0.011277223729341881, model__max_depth=6, model__min_child_samples=20, model__min_child_weight=0.001, model__n_estimators=489, model__num_leaves=76, model__reg_alpha=0.3925879806965068, model__reg_lambda=0.09983689107917987, model__subsample=0.8056937753654446; f1: (test=0.567) f2: (test=0.389) pr_auc: (test=0.268) precision: (test=0.200) recall: (test=0.510) roc_auc: (test=0.700) total time=  27.9s\n",
      "[CV 3/5] END model__colsample_bytree=0.8447411578889518, model__learning_rate=0.011277223729341881, model__max_depth=6, model__min_child_samples=20, model__min_child_weight=0.001, model__n_estimators=489, model__num_leaves=76, model__reg_alpha=0.3925879806965068, model__reg_lambda=0.09983689107917987, model__subsample=0.8056937753654446; f1: (test=0.585) f2: (test=0.449) pr_auc: (test=0.296) precision: (test=0.221) recall: (test=0.606) roc_auc: (test=0.726) total time=  28.3s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pkg_resources\")\n",
    "\n",
    "# ============================================\n",
    "# 1. í´ë˜ìŠ¤ ë¹„ìœ¨ í™•ì¸\n",
    "# ============================================\n",
    "print(\"=\"*60)\n",
    "print(\"í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„\")\n",
    "print(\"=\"*60)\n",
    "print(y_train.value_counts().sort_index())\n",
    "print(f\"\\në¹„ìœ¨:\")\n",
    "print(y_train.value_counts(normalize=True).sort_index())\n",
    "\n",
    "# âœ… ìˆ˜ì •: 0ì´ ì¼ë°˜ê°€(ë‹¤ìˆ˜), 1ì´ ê°€ê²©ë¯¸ë‹¬(ì†Œìˆ˜)\n",
    "majority_count = (y_train == 0).sum()   # ì¼ë°˜ê°€ (ë‹¤ìˆ˜) - ì•½ 90%\n",
    "minority_count = (y_train == 1).sum()   # ê°€ê²©ë¯¸ë‹¬ (ì†Œìˆ˜) - ì•½ 10%\n",
    "\n",
    "print(f\"\\ní´ë˜ìŠ¤ êµ¬ì„±:\")\n",
    "print(f\"   0 (ì¼ë°˜ê°€, ë‹¤ìˆ˜): {majority_count}ê°œ ({majority_count/len(y_train)*100:.1f}%)\")\n",
    "print(f\"   1 (ê°€ê²©ë¯¸ë‹¬, ì†Œìˆ˜): {minority_count}ê°œ ({minority_count/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "# âœ… scale_pos_weight: ì–‘ì„± í´ë˜ìŠ¤(1=ê°€ê²©ë¯¸ë‹¬=ì†Œìˆ˜)ì— ëŒ€í•œ ê°€ì¤‘ì¹˜\n",
    "# ê³µì‹: (ë‹¤ìˆ˜ í´ë˜ìŠ¤ ê°œìˆ˜) / (ì†Œìˆ˜ í´ë˜ìŠ¤ ê°œìˆ˜)\n",
    "scale_pos_weight = majority_count / minority_count\n",
    "\n",
    "print(f\"\\nê³„ì‚°ëœ scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "print(f\"   â†’ LightGBMì€ ìë™ìœ¼ë¡œ í´ë˜ìŠ¤ 1(ê°€ê²©ë¯¸ë‹¬)ì— ì´ ê°€ì¤‘ì¹˜ ì ìš©\")\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ í™•ì¸\n",
    "print(\"\\nê²°ì¸¡ì¹˜ í˜„í™©:\")\n",
    "missing_info = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'ê²°ì¸¡_ê°œìˆ˜': X_train.isnull().sum().values,\n",
    "    'ê²°ì¸¡_ë¹„ìœ¨(%)': (X_train.isnull().mean() * 100).values\n",
    "}).sort_values('ê²°ì¸¡_ë¹„ìœ¨(%)', ascending=False)\n",
    "print(missing_info.head(10))\n",
    "print(f\"\\nì „ì²´ ê²°ì¸¡ ë¹„ìœ¨: {X_train.isnull().mean().mean()*100:.1f}%\")\n",
    "print(f\"Feature ê°œìˆ˜: {X_train.shape[1]}ê°œ\")\n",
    "\n",
    "# ============================================\n",
    "# 2. Pipeline êµ¬ì„±\n",
    "# ============================================\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    ('model', LGBMClassifier(\n",
    "        objective='binary',\n",
    "        device='cpu',\n",
    "        random_state=42,\n",
    "        verbosity=-1,\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=scale_pos_weight,  # âœ… ìë™ìœ¼ë¡œ pos_label=1ì— ì ìš©\n",
    "        force_col_wise=True,\n",
    "        metric='None',  # ğŸ”¥ ì¶”ê°€: ê¸°ë³¸ ë©”íŠ¸ë¦­ ë„ê¸°\n",
    "        # ë²”ì£¼í˜• ê´€ë ¨ íŒŒë¼ë¯¸í„°\n",
    "        cat_smooth=10,\n",
    "        cat_l2=10,\n",
    "        max_cat_threshold=32,\n",
    "        max_cat_to_onehot=4\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"\\nâœ… Pipeline êµ¬ì„±:\")\n",
    "print(\"   1. LGBMClassifier (GPU)\")\n",
    "print(f\"      - scale_pos_weight={scale_pos_weight:.2f} (í´ë˜ìŠ¤ 1=ê°€ê²©ë¯¸ë‹¬ ê°€ì¤‘ì¹˜)\")\n",
    "\n",
    "# ============================================\n",
    "# 3. íŒŒë¼ë¯¸í„° ë¶„í¬\n",
    "# ============================================\n",
    "print(f\"\\nì†Œìˆ˜ í´ë˜ìŠ¤(1=ê°€ê²©ë¯¸ë‹¬) ìƒ˜í”Œ ìˆ˜: {minority_count}ê°œ\")\n",
    "\n",
    "param_distributions = {\n",
    "    # ğŸ”¥ LightGBM íŒŒë¼ë¯¸í„° - ì†Œìˆ˜ í´ë˜ìŠ¤ ë¯¼ê°ë„ í–¥ìƒ\n",
    "    'model__n_estimators': randint(300, 1000),\n",
    "    'model__learning_rate': uniform(0.005, 0.045),\n",
    "    'model__max_depth': randint(3, 8),\n",
    "    'model__num_leaves': randint(15, 80),\n",
    "    'model__min_child_samples': randint(5, 50),\n",
    "    'model__subsample': uniform(0.6, 0.4),\n",
    "    'model__colsample_bytree': uniform(0.6, 0.4),\n",
    "    'model__min_child_weight': [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    'model__reg_alpha': uniform(0, 0.5),\n",
    "    'model__reg_lambda': uniform(0, 0.5),\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 4. Scoring ì„¤ì •\n",
    "# ============================================\n",
    "\n",
    "scoring = {\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f2': make_scorer(fbeta_score, beta=2),              \n",
    "    'pr_auc': make_scorer(average_precision_score, response_method='predict_proba'),\n",
    "    'precision': make_scorer(precision_score, zero_division=0),\n",
    "    'f1': make_scorer(f1_score, zero_division=0, average='macro'),\n",
    "    'roc_auc': 'roc_auc'                                           \n",
    "}\n",
    "\n",
    "main_score = 'pr_auc'\n",
    "\n",
    "print(\"\\nâœ… Scoring ì „ëµ:\")\n",
    "print(f\"   ë©”ì¸ ëª©í‘œ: {main_score.upper()}\")\n",
    "print(f\"   íƒ€ê¹ƒ: í´ë˜ìŠ¤ 1 (ê°€ê²©ë¯¸ë‹¬) ê²€ì¶œ ìµœì í™”\")\n",
    "print(f\"   pos_label: 1 (ê¸°ë³¸ê°’, ìƒëµ ê°€ëŠ¥)\")\n",
    "\n",
    "# ============================================\n",
    "# 5. Stratified K-Fold\n",
    "# ============================================\n",
    "n_folds = 5\n",
    "n_iter = 150\n",
    "cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "print(f\"\\nêµì°¨ê²€ì¦ Folds: {n_folds}\")\n",
    "print(f\"ëœë¤ ìƒ˜í”Œë§ ì¡°í•© ìˆ˜: {n_iter}ê°œ\")\n",
    "print(f\"ì´ Fits: {n_iter} Ã— {n_folds} = {n_iter * n_folds}\")\n",
    "\n",
    "# ============================================\n",
    "# 6. RandomizedSearchCV ì‹¤í–‰\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸš€ RandomizedSearchCV ì‹œì‘!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "lgbm_random = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=n_iter,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    refit=main_score,\n",
    "    verbose=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    error_score=np.nan \n",
    ")\n",
    "\n",
    "start_actual = time.time()\n",
    "lgbm_random.fit(X_train, y_train)\n",
    "actual_time = time.time() - start_actual\n",
    "\n",
    "# ============================================\n",
    "# 7. ê²°ê³¼ ì¶œë ¥\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… ì™„ë£Œ!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"â±ï¸  ì†Œìš” ì‹œê°„: {actual_time/60:.1f}ë¶„ ({actual_time:.0f}ì´ˆ)\")\n",
    "\n",
    "print(f\"\\nğŸ† ìµœê³  {main_score.upper()} (CV): {lgbm_random.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ“‹ ìµœì  íŒŒë¼ë¯¸í„°:\")\n",
    "for key, value in sorted(lgbm_random.best_params_.items()):\n",
    "    if isinstance(value, float):\n",
    "        print(f\"   {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"   {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def4977",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================\n",
    "# 8. ì „ì²´ ê²°ê³¼ ë¹„êµ\n",
    "# ============================================\n",
    "results_df = pd.DataFrame(lgbm_random.cv_results_)\n",
    "\n",
    "scoring_cols = [f'mean_test_{score}' for score in scoring.keys()]\n",
    "\n",
    "comparison_cols = [f'rank_test_{main_score}'] + scoring_cols + ['params']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ“Š ìƒìœ„ 10ê°œ íŒŒë¼ë¯¸í„° ì¡°í•© ({main_score.upper()} ê¸°ì¤€)\")\n",
    "print(\"=\"*60)\n",
    "top_10 = results_df[comparison_cols].sort_values(f'rank_test_{main_score}').head(10)\n",
    "\n",
    "for idx, row in top_10.iterrows():\n",
    "    rank = int(row[f'rank_test_{main_score}'])\n",
    "    pr_auc = row[f'mean_test_pr_auc']\n",
    "    recall = row['mean_test_recall']\n",
    "    f2 = row['mean_test_f2']\n",
    "    precision = row['mean_test_precision']\n",
    "    f1 = row['mean_test_f1']\n",
    "    \n",
    "    print(f\"\\n#{rank} - {main_score.upper()}: {row[f'mean_test_{main_score}']:.4f} | Recall: {recall:.4f}\")\n",
    "    print(f\"   F2: {f2:.3f} | Precision: {precision:.3f} | F1: {f1:.3f}\")\n",
    "    \n",
    "    params = row['params']\n",
    "    print(f\"   Model: lr={params.get('model__learning_rate', 0):.4f}, \"\n",
    "          f\"depth={params.get('model__max_depth', 0)}, \"\n",
    "          f\"leaves={params.get('model__num_leaves', 0)}\")\n",
    "\n",
    "# ============================================\n",
    "# 9. í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ§ª í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_model = lgbm_random.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "# âœ… í´ë˜ìŠ¤ 1(ê°€ê²©ë¯¸ë‹¬)ì˜ í™•ë¥  ì¶”ì¶œ\n",
    "y_pred_proba_minority = y_pred_proba[:, 1]  # âœ… ì¸ë±ìŠ¤ 1 = í´ë˜ìŠ¤ 1 = ê°€ê²©ë¯¸ë‹¬\n",
    "\n",
    "print(classification_report(\n",
    "    y_test, y_pred, \n",
    "    target_names=['0 (ì¼ë°˜ê°€, ë‹¤ìˆ˜)', '1 (ê°€ê²©ë¯¸ë‹¬, ì†Œìˆ˜)']\n",
    "))\n",
    "\n",
    "print(\"\\ní˜¼ë™ í–‰ë ¬:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index=['ì‹¤ì œ_0 (ì¼ë°˜ê°€)', 'ì‹¤ì œ_1 (ê°€ê²©ë¯¸ë‹¬)'],\n",
    "                     columns=['ì˜ˆì¸¡_0 (ì¼ë°˜ê°€)', 'ì˜ˆì¸¡_1 (ê°€ê²©ë¯¸ë‹¬)'])\n",
    "print(cm_df)\n",
    "\n",
    "# âœ… í˜¼ë™ í–‰ë ¬ í•´ì„ ìˆ˜ì •\n",
    "# confusion_matrix êµ¬ì¡°:\n",
    "#              ì˜ˆì¸¡_0  ì˜ˆì¸¡_1\n",
    "# ì‹¤ì œ_0 (ì¼ë°˜ê°€)  TN      FP\n",
    "# ì‹¤ì œ_1 (ê°€ê²©ë¯¸ë‹¬)   FN      TP\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"\\nğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ í•´ì„ (ì†Œìˆ˜ í´ë˜ìŠ¤=1=ê°€ê²©ë¯¸ë‹¬ ê¸°ì¤€):\")\n",
    "print(f\"   âœ… ì •í™•í•œ ë¶„ë¥˜: {tn + tp}ê°œ ({(tn+tp)/len(y_test)*100:.1f}%)\")\n",
    "print(f\"   âš ï¸  ì˜¤íƒ (FP): {fp}ê°œ â†’ ì¼ë°˜ê°€ì„ ê°€ê²©ë¯¸ë‹¬ë¡œ ì˜¤íŒ (ì¬ê²€ì‚¬ í•„ìš”)\")\n",
    "print(f\"   ğŸš¨ ë¯¸íƒ (FN): {fn}ê°œ â†’ ê°€ê²©ë¯¸ë‹¬ë¥¼ ì¼ë°˜ê°€ìœ¼ë¡œ ì˜¤íŒ (ì¹˜ëª…ì !)\")\n",
    "\n",
    "# âœ… Recall ê³„ì‚°: TP / (TP + FN)\n",
    "if tp + fn > 0:\n",
    "    recall_pct = tp/(tp+fn)*100\n",
    "    print(f\"\\n   ğŸ“Š ì†Œìˆ˜ í´ë˜ìŠ¤(1=ê°€ê²©ë¯¸ë‹¬) Recall: {recall_pct:.1f}%\")\n",
    "    print(f\"      â†’ ê°€ê²©ë¯¸ë‹¬ {tp+fn}ê°œ ì¤‘ {tp}ê°œ ê²€ì¶œ ({fn}ê°œ ë†“ì¹¨)\")\n",
    "else:\n",
    "    print(f\"\\n   ğŸ“Š ì†Œìˆ˜ í´ë˜ìŠ¤(1=ê°€ê²©ë¯¸ë‹¬) Recall: N/A\")\n",
    "\n",
    "# âœ… Precision ê³„ì‚°: TP / (TP + FP)\n",
    "if tp + fp > 0:\n",
    "    precision_pct = tp/(tp+fp)*100\n",
    "    print(f\"   ğŸ“Š ì†Œìˆ˜ í´ë˜ìŠ¤(1=ê°€ê²©ë¯¸ë‹¬) Precision: {precision_pct:.1f}%\")\n",
    "    print(f\"      â†’ ê°€ê²©ë¯¸ë‹¬ íŒì • {tp+fp}ê°œ ì¤‘ {tp}ê°œ ì •ë‹µ\")\n",
    "else:\n",
    "    print(f\"   ğŸ“Š ì†Œìˆ˜ í´ë˜ìŠ¤(1=ê°€ê²©ë¯¸ë‹¬) Precision: N/A\")\n",
    "\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba_minority)\n",
    "print(f\"   ğŸ“Š ROC-AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# 10. ğŸ”¥ ì„ê³„ê°’ ì¡°ì •ìœ¼ë¡œ ì¶”ê°€ ê°œì„ \n",
    "# ============================================\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "# âœ… pos_label=1 (ê°€ê²©ë¯¸ë‹¬) ê¸°ì¤€ìœ¼ë¡œ PR ê³¡ì„  ê³„ì‚°\n",
    "precisions, recalls, thresholds = precision_recall_curve(\n",
    "    y_test, y_pred_proba_minority\n",
    ")\n",
    "\n",
    "# Recall 80% ë³´ì¥\n",
    "target_recall = 0.80\n",
    "idx = np.where(recalls >= target_recall)[0]\n",
    "\n",
    "if len(idx) > 0:\n",
    "    best_idx = idx[np.argmax(precisions[idx])]\n",
    "    optimal_threshold = thresholds[best_idx]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ğŸ¯ Recall {target_recall*100}% ë³´ì¥ ì‹œ ìµœì  ì„ê³„ê°’\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"ìµœì  ì„ê³„ê°’: {optimal_threshold:.3f} (ê¸°ë³¸ê°’ 0.5)\")\n",
    "    print(f\"Precision: {precisions[best_idx]:.3f}\")\n",
    "    print(f\"Recall: {recalls[best_idx]:.3f}\")\n",
    "    \n",
    "    # âœ… ì„ê³„ê°’ ì¡°ì •: í™•ë¥  >= thresholdì´ë©´ í´ë˜ìŠ¤ 1(ê°€ê²©ë¯¸ë‹¬)ë¡œ ì˜ˆì¸¡\n",
    "    y_pred_adjusted = (y_pred_proba_minority >= optimal_threshold).astype(int)\n",
    "    \n",
    "    cm_adj = confusion_matrix(y_test, y_pred_adjusted)\n",
    "    tn2, fp2, fn2, tp2 = cm_adj.ravel()\n",
    "    \n",
    "    print(f\"\\nì¡°ì • íš¨ê³¼:\")\n",
    "    print(f\"   ë¯¸íƒ(FN) ê°ì†Œ: {fn} â†’ {fn2} (ê°œì„ : {fn-fn2}ê°œ)\")\n",
    "    print(f\"   ì˜¤íƒ(FP) ì¦ê°€: {fp} â†’ {fp2} (ì¦ê°€: {fp2-fp}ê°œ)\")\n",
    "    \n",
    "    if tp + fn > 0 and tp2 + fn2 > 0:\n",
    "        print(f\"   Recall ê°œì„ : {tp/(tp+fn)*100:.1f}% â†’ {tp2/(tp2+fn2)*100:.1f}%\")\n",
    "    \n",
    "    if fn > fn2:\n",
    "        print(f\"   ğŸ’¡ ê°€ê²©ë¯¸ë‹¬ë¥¼ ì¼ë°˜ê°€ìœ¼ë¡œ ì˜¤íŒí•˜ëŠ” ì¹˜ëª…ì  ì˜¤ë¥˜ {fn-fn2}ê°œ ê°ì†Œ!\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  Recall {target_recall*100}% ë‹¬ì„± ë¶ˆê°€ (ìµœëŒ€ Recall: {recalls.max():.2%})\")\n",
    "\n",
    "# ============================================\n",
    "# 11. ë³€ìˆ˜ ì¤‘ìš”ë„ í™•ì¸\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“Š ë³€ìˆ˜ ì¤‘ìš”ë„ Top 10\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_model = best_model.named_steps['model']\n",
    "feature_names = list(X_train.columns)\n",
    "\n",
    "n_features_used = len(final_model.feature_importances_)\n",
    "feature_names = feature_names[:n_features_used]\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(importance_df.head(10).to_string(index=False))\n",
    "\n",
    "# ============================================\n",
    "# 12. êµì°¨ê²€ì¦ vs í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ë¹„êµ\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ: êµì°¨ê²€ì¦ vs í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# âœ… pos_label=1 ê¸°ë³¸ê°’ ì‚¬ìš©\n",
    "test_metrics = {\n",
    "    'PR-AUC': average_precision_score(y_test, y_pred_proba_minority),\n",
    "    'Recall': recall_score(y_test, y_pred),\n",
    "    'F2': fbeta_score(y_test, y_pred, beta=2),\n",
    "    'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "    'F1': f1_score(y_test, y_pred, zero_division=0),\n",
    "    'ROC-AUC': test_roc_auc\n",
    "}\n",
    "\n",
    "print(f\"{'ì§€í‘œ':<15} {'êµì°¨ê²€ì¦ (CV)':<20} {'í…ŒìŠ¤íŠ¸':<15} {'ì°¨ì´':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for metric in ['PR-AUC', 'Recall', 'F2', 'Precision', 'F1', 'ROC-AUC']:\n",
    "    cv_key = metric.lower().replace('-', '_')\n",
    "    cv_score = results_df.loc[results_df[f'rank_test_{main_score}'] == 1, f'mean_test_{cv_key}'].values[0]\n",
    "    test_score = test_metrics[metric]\n",
    "    diff = test_score - cv_score\n",
    "    \n",
    "    diff_str = f\"{diff:+.4f}\"\n",
    "    if abs(diff) > 0.05:\n",
    "        diff_str += \" âš ï¸\"\n",
    "    \n",
    "    print(f\"{metric:<15} {cv_score:<20.4f} {test_score:<15.4f} {diff_str}\")\n",
    "\n",
    "# ============================================\n",
    "# 13. ìµœì¢… ìš”ì•½\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ“ ìµœì¢… ìš”ì•½ ({main_score.upper()} ìµœì í™”)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ… ìµœì  ëª¨ë¸ {main_score.upper()} (CV): {lgbm_random.best_score_:.4f}\")\n",
    "print(f\"âœ… í…ŒìŠ¤íŠ¸ Recall: {test_metrics['Recall']*100:.1f}% (ê°€ê²©ë¯¸ë‹¬ ê²€ì¶œë¥ )\")\n",
    "print(f\"âœ… í…ŒìŠ¤íŠ¸ Precision: {test_metrics['Precision']*100:.1f}% (ê°€ê²©ë¯¸ë‹¬ íŒì • ì •í™•ë„)\")\n",
    "print(f\"âœ… í…ŒìŠ¤íŠ¸ F1: {test_metrics['F1']:.4f}\")\n",
    "print(f\"âœ… ì¹˜ëª…ì  ì˜¤ë¥˜(ë¯¸íƒ FN): {fn}ê°œ / {tp+fn}ê°œ\")\n",
    "print(f\"â±ï¸  ì´ ì†Œìš” ì‹œê°„: {actual_time/60:.1f}ë¶„\")\n",
    "\n",
    "print(\"\\nğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸:\")\n",
    "print(f\"   - ê°€ê²©ë¯¸ë‹¬(1) {tp+fn}ê°œ ì¤‘ {tp}ê°œ ê²€ì¶œ ({tp/(tp+fn)*100:.1f}%)\")\n",
    "print(f\"   - ë†“ì¹œ ê°€ê²©ë¯¸ë‹¬: {fn}ê°œ\")\n",
    "print(f\"   - ì˜¤íƒ (ì¼ë°˜ê°€â†’ê°€ê²©ë¯¸ë‹¬): {fp}ê°œ (ì¬ê²€ì‚¬ í•„ìš”)\")\n",
    "\n",
    "# ============================================\n",
    "# 14. ëª¨ë¸ + íŒŒë¼ë¯¸í„° ì €ì¥\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ’¾ ëª¨ë¸ ë° íŒŒë¼ë¯¸í„° ì €ì¥\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "save_model_input = input(\"ëª¨ë¸ì„ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): \")\n",
    "if save_model_input.lower() == 'y':\n",
    "    \n",
    "    # MODEL_DIRì´ ì •ì˜ë˜ì§€ ì•Šì€ ê²½ìš° í˜„ì¬ ë””ë ‰í† ë¦¬ ì‚¬ìš©\n",
    "    try:\n",
    "        MODEL_DIR = Path(MODEL_DIR)\n",
    "    except:\n",
    "        MODEL_DIR = Path('.')\n",
    "        print(f\"âš ï¸  MODEL_DIR ë¯¸ì •ì˜, í˜„ì¬ ë””ë ‰í† ë¦¬ ì‚¬ìš©: {MODEL_DIR.absolute()}\")\n",
    "    \n",
    "    MODEL_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    model_filename = MODEL_DIR / f'best_lgbm_{main_score}_optimized_{timestamp}.pkl'\n",
    "    params_filename = MODEL_DIR / f'best_params_{main_score}_{timestamp}.json'\n",
    "    metrics_filename = MODEL_DIR / f'test_metrics_{main_score}_{timestamp}.json'\n",
    "    results_filename = MODEL_DIR / f'cv_results_{main_score}_{timestamp}.csv'\n",
    "    \n",
    "    # 1. ëª¨ë¸ ì €ì¥\n",
    "    joblib.dump(best_model, model_filename)\n",
    "    print(f\"âœ… ëª¨ë¸ ì €ì¥: {model_filename}\")\n",
    "    \n",
    "    # 2. íŒŒë¼ë¯¸í„° ì €ì¥\n",
    "    best_params_serializable = {}\n",
    "    for key, value in lgbm_random.best_params_.items():\n",
    "        if isinstance(value, (np.integer, np.floating)):\n",
    "            best_params_serializable[key] = float(value) if isinstance(value, np.floating) else int(value)\n",
    "        else:\n",
    "            best_params_serializable[key] = value\n",
    "    \n",
    "    params_info = {\n",
    "        'best_params': best_params_serializable,\n",
    "        f'best_{main_score}_score': float(lgbm_random.best_score_),\n",
    "        'optimization_target': main_score,\n",
    "        'cv_folds': n_folds,\n",
    "        'n_iter': n_iter,\n",
    "        'timestamp': timestamp,\n",
    "        'class_labels': {\n",
    "            '0': 'ì¼ë°˜ê°€ (ë‹¤ìˆ˜)',\n",
    "            '1': 'ê°€ê²©ë¯¸ë‹¬ (ì†Œìˆ˜)'\n",
    "        },\n",
    "        'minority_count': int(minority_count),\n",
    "        'majority_count': int(majority_count),\n",
    "        'scale_pos_weight': float(scale_pos_weight)\n",
    "    }\n",
    "    \n",
    "    with open(params_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(params_info, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"âœ… íŒŒë¼ë¯¸í„° ì €ì¥: {params_filename}\")\n",
    "    \n",
    "    # 3. í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ì €ì¥\n",
    "    test_metrics_serializable = {\n",
    "        key: float(value) if isinstance(value, (np.floating, np.integer)) else value\n",
    "        for key, value in test_metrics.items()\n",
    "    }\n",
    "    \n",
    "    metrics_info = {\n",
    "        'test_metrics': test_metrics_serializable,\n",
    "        'confusion_matrix': {\n",
    "            'tn': int(tn),  # ì¼ë°˜ê°€ â†’ ì¼ë°˜ê°€ (ì •ë‹µ)\n",
    "            'fp': int(fp),  # ì¼ë°˜ê°€ â†’ ê°€ê²©ë¯¸ë‹¬ (ì˜¤íƒ)\n",
    "            'fn': int(fn),  # ê°€ê²©ë¯¸ë‹¬ â†’ ì¼ë°˜ê°€ (ë¯¸íƒ, ì¹˜ëª…ì !)\n",
    "            'tp': int(tp)   # ê°€ê²©ë¯¸ë‹¬ â†’ ê°€ê²©ë¯¸ë‹¬ (ì •ë‹µ)\n",
    "        },\n",
    "        'business_interpretation': {\n",
    "            'total_minority': int(tp + fn),      # ì‹¤ì œ ê°€ê²©ë¯¸ë‹¬ ê°œìˆ˜\n",
    "            'detected_minority': int(tp),        # ê²€ì¶œëœ ê°€ê²©ë¯¸ë‹¬\n",
    "            'missed_minority': int(fn),          # ë†“ì¹œ ê°€ê²©ë¯¸ë‹¬ (ì¹˜ëª…ì )\n",
    "            'recall_percentage': float(tp/(tp+fn)*100) if (tp+fn) > 0 else 0,\n",
    "            'false_alarms': int(fp)              # ì¼ë°˜ê°€ì„ ê°€ê²©ë¯¸ë‹¬ë¡œ ì˜¤íŒ\n",
    "        },\n",
    "        'timestamp': timestamp\n",
    "    }\n",
    "    \n",
    "    with open(metrics_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metrics_info, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"âœ… í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ì €ì¥: {metrics_filename}\")\n",
    "    \n",
    "    # 4. CV ê²°ê³¼ ì €ì¥\n",
    "    results_df.to_csv(results_filename, index=False, encoding='utf-8')\n",
    "    print(f\"âœ… CV ê²°ê³¼ ì €ì¥: {results_filename}\")\n",
    "    \n",
    "    print(\"\\nğŸ“¦ ì €ì¥ëœ íŒŒì¼ ìš”ì•½:\")\n",
    "    print(f\"1. ëª¨ë¸: {model_filename.name}\")\n",
    "    print(f\"2. íŒŒë¼ë¯¸í„°: {params_filename.name}\")\n",
    "    print(f\"3. ì„±ëŠ¥: {metrics_filename.name}\")\n",
    "    print(f\"4. CVê²°ê³¼: {results_filename.name}\")\n",
    "    \n",
    "else:\n",
    "    print(\"ëª¨ë¸ ì €ì¥ ìƒëµ\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0ceb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    'best_lgbm_smote_random',\n",
    "    'best_lgbm_smote_20251106_155837',\n",
    "    'best_lgbm_recall_optimized_20251106_162548',\n",
    "    'best_lgbm_recall_optimized_20251106_201626',\n",
    "    'best_lgbm_pr_auc_optimized_20251106_215224'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caead454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "loaded_model = joblib.load(MODEL_DIR / 'best_lgbm_pr_auc_optimized_20251106_215224.pkl')\n",
    "predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df76826",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f983bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647723e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ì…‹ ì„±ëŠ¥ í‰ê°€\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_prob = loaded_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "# Balanced Accuracy\n",
    "bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nBalanced Accuracy (Test Set): {bal_acc:.3f}\")\n",
    "\n",
    "# ROC-AUC (OvO, macro)\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y_train))\n",
    "roc_auc_ovo = roc_auc_score(y_test_bin, y_prob, average='macro')\n",
    "print(f\"ROC-AUC (OvO, macro, Test Set): {roc_auc_ovo:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b42bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loaded_model.named_steps['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73915e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# SHAP ì ìš©\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Plot\n",
    "shap.summary_plot(shap_values, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f673f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean absolute shap value per feature\n",
    "shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "print(shap_importance)\n",
    "shap_df = pd.DataFrame({\n",
    "    'feature': X_test.columns,\n",
    "    'shap_importance': shap_importance\n",
    "}).sort_values(by='shap_importance', ascending=False)\n",
    "\n",
    "print(shap_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartfarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
